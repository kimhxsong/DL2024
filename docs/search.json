[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "딥러닝 (2024)",
    "section": "",
    "text": "질문하는 방법\n\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 이메일로 미리 시간을 정할 것\n카카오톡: http://pf.kakao.com/_txeIFG/chat\n\n강의노트\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nApr 3, 2024\n\n\n06wk-1: 합성곱신경망 (2)\n\n\n최규빈 \n\n\n\n\nApr 3, 2024\n\n\n05wk-2: 합성곱신경망 (1)\n\n\n최규빈 \n\n\n\n\nApr 1, 2024\n\n\n05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy\n\n\n최규빈 \n\n\n\n\nMar 27, 2024\n\n\n04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현\n\n\n최규빈 \n\n\n\n\nMar 25, 2024\n\n\n04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST\n\n\n최규빈 \n\n\n\n\nMar 20, 2024\n\n\n03wk-2: 깊은신경망 (1) – 로지스틱의 한계 극복\n\n\n최규빈 \n\n\n\n\nMar 18, 2024\n\n\n03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계\n\n\n최규빈 \n\n\n\n\nMar 13, 2024\n\n\n02wk-2: 회귀분석 (3) – Step1,2,4 의 변형\n\n\n최규빈 \n\n\n\n\nMar 11, 2024\n\n\n02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분\n\n\n최규빈 \n\n\n\n\nMar 6, 2024\n\n\n01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법\n\n\n최규빈 \n\n\n\n\nMar 4, 2024\n\n\n01wk-1: 이미지 자료 분석 (겉핥기)\n\n\n최규빈 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/02wk-1.html#a.-소설",
    "href": "posts/02wk-1.html#a.-소설",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 소설",
    "text": "A. 소설\n- 카페주인인 박혜원씨는 온도와 아이스아메리카노 판매량이 관계가 있다는 것을 알았다. 구체적으로는\n\n“온도가 높아질 수록 (=날씨가 더울수록) 아이스아메리카노의 판매량이 증가”\n\n한다는 사실을 알게 되었다. 박혜원씨는\n\n일기예보를 보고 오늘의 평균 기온을 입력하면, 오늘의 아이스아메리카노 판매량을 미리 예측할 수 있지 않을까? 그 예측량만큼 아이스아메리카노를 준비하면 장사에 도움이 되지 않을까???\n\n라는 생각을 하게 되었고 이를 위하여 아래와 같이 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n여기에서 temp는 평균기온이고, sales는 아이스아메리카노 판매량이다.1 평균기온과 판매량의 그래프를 그려보면 아래와 같다.\n1 판매량이 소수점이고 심지어 음수인것은 그냥 그려러니 하자..\nplt.plot(temp,sales,'o')"
  },
  {
    "objectID": "posts/02wk-1.html#b.-모델링",
    "href": "posts/02wk-1.html#b.-모델링",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 모델링",
    "text": "B. 모델링\n- 산점도를 살펴본 박혜원씨는 평균기온이 올라갈수록 아이스아메리카노 판매량이 “선형적”으로 증가한다는 사실을 캐치했다. 물론 약간의 오차는 있어보였다. 오차까지 고려하여 평균기온과 아이스판매량의 관계를 추정하면 아래와 같이 생각할 수 있다.\n\n아이스아메리카노 판매량 \\(\\approx\\) \\(w_0\\) \\(+\\) \\(w_1\\) \\(\\times\\) 평균기온\n\n위의 수식에서 만약에 \\(w_0\\)와 \\(w_1\\)의 값을 적절히 추정한다면, 평균기온량을 입력으로 하였을때 아이스아메리카노 판매량을 예측할 수 있을 것이다.\n- 아이스크림 판매량을 \\(y_i\\)로, 평균기온을 \\(x_i\\)로 변수화한뒤 박혜원의 수식을 좀 더 수학적으로 표현하면\n\\[y_i \\approx w_0 + w_1 x_i,\\quad i=1,2,\\dots,100\\]\n와 같이 쓸 수 있다. 오차항을 포함하여 좀 더 엄밀하게 쓰면\n\\[y_i = w_0 + w_1 x_i + \\epsilon_i,\\quad i=1,2,\\dots,100\\]\n와 같이 나타낼 수 있어보인다. 여기에서 \\(\\epsilon_i \\sim N(0,\\sigma^2)\\) 로 가정해도 무방할 듯 하다. 그런데 이를 다시 아래와 같이 표현하는 것이 가능하다.\n\\[{\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\]\n단 여기에서\n\\[{\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf x}=\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\dots \\\\ x_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} {\\bf 1} & {\\bf x} \\end{bmatrix}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\]\n이다."
  },
  {
    "objectID": "posts/02wk-1.html#c.-데이터를-torch.tensor로-변환",
    "href": "posts/02wk-1.html#c.-데이터를-torch.tensor로-변환",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 데이터를 torch.tensor로 변환",
    "text": "C. 데이터를 torch.tensor로 변환\n- 현재까지의 상황을 파이토치로 코딩하면 아래와 같다.\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n#W = ?? 이건 모름.. 추정해야함. \n#ϵ = ?? 이것도 모름!!"
  },
  {
    "objectID": "posts/02wk-1.html#d.-아무렇게나-추정",
    "href": "posts/02wk-1.html#d.-아무렇게나-추정",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 아무렇게나 추정",
    "text": "D. 아무렇게나 추정\n- \\({\\bf W}\\) 에 대한 추정값을 \\(\\hat{\\bf W}\\)라고 할때\n\\[\\hat{\\bf W}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix} =\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\]\n으로 추정한 상황이라면 커피판매량의 예측값은\n\\[\\hat{\\bf y} = {\\bf X}\\hat{\\bf W}\\]\n이라고 표현할 수 있다. 이 의미는 아래의 그림에서 주황색 점선으로 커피판매량을 예측한다는 의미이다.\n\nWhat = torch.tensor([[-5.0],\n                     [10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')"
  },
  {
    "objectID": "posts/02wk-1.html#e.-추정의-방법",
    "href": "posts/02wk-1.html#e.-추정의-방법",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "E. 추정의 방법",
    "text": "E. 추정의 방법\n- 방법1: 이론적으로 추론 &lt;- 회귀분석시간에 배운것\n\ntorch.linalg.inv((X.T @ X)) @ X.T @ y # 공식~\n\ntensor([[2.4459],\n        [4.0043]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.4459 + 4.0043*x,'--')\n\n\n\n\n\n\n\n\n- 방법2: 컴퓨터의 반복계산을 이용하여 추론 (손실함수도입 + 경사하강법)\n\n1단계: 아무 점선이나 그어본다..\n2단계: 1단계에서 그은 점선보다 더 좋은 점선으로 바꾼다.\n3단계: 1-2단계를 반복한다."
  },
  {
    "objectID": "posts/02wk-1.html#a.-문제셋팅-다시-복습",
    "href": "posts/02wk-1.html#a.-문제셋팅-다시-복습",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 문제셋팅 다시 복습",
    "text": "A. 문제셋팅 다시 복습\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)"
  },
  {
    "objectID": "posts/02wk-1.html#b.-1단계-최초의-점선",
    "href": "posts/02wk-1.html#b.-1단계-최초의-점선",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 1단계 – 최초의 점선",
    "text": "B. 1단계 – 최초의 점선\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거"
  },
  {
    "objectID": "posts/02wk-1.html#c.-2단계-update",
    "href": "posts/02wk-1.html#c.-2단계-update",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 2단계 – update",
    "text": "C. 2단계 – update\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\[loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n- loss 함수의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다.\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다.\n(중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6240, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6240)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다.\n\n- 발상의 전환: 가만히 보니까 loss는 \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 에 따라서 값이 바뀌는 함수잖아??? 즉 아래와 같이 생각할 수 있음.\n\\[ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n따라서 구하고 싶은것은 아래와 같음\n\\[\\hat{\\bf W} := \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\n- \\(loss({\\bf W})\\)를 최소로 만드는 \\({\\bf W}\\)를 컴퓨터로 구하는 방법, 즉 \\(\\hat{\\bf W} := \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\)를 구하는 방법을 요약하면 아래와 같다.\n1. 임의의 점 \\(\\hat{\\bf W}\\)를 찍는다.\n2. 그 점에서 순간기울기를 구한다. 즉 \\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\) 를 계산한다.\n3. \\(\\hat{\\bf W}\\)에서의 순간기울기2의 부호를 살펴보고 부호와 반대방향으로 움직인다. 이때 기울기의 절대값 크기3와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. 즉 아래의 수식에 따라 업데이트 한다.\n2 \\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\)3 \\(\\left|\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|\\)\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\]\n- 여기에서 미분을 어떻게…?? 즉 아래를 어떻게 계산해..?\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix} \\]\n\nloss.backward()를 실행하면 What.grad에 미분값이 업데이트 되어요!\n\n(실행전)\n\nprint(What.grad)\n\nNone\n\n\n(실행후)\n\nloss.backward()\n\n\nprint(What.grad)\n\ntensor([[-1342.2465],\n        [ 1188.9203]])\n\n\n- 계산결과의 검토 (1)\n\n\\(loss({\\bf W})=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([[-1342.2466],\n        [ 1188.9198]], grad_fn=&lt;AddBackward0&gt;)\n\n\n- 계산결과의 검토 (2)\n\\[\\frac{\\partial}{\\partial {\\bf W} } loss({\\bf W})=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss({\\bf W}) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\]\n를 계산하고 싶은데 벡터미분을 할줄 모른다고 하자. 편미분의 정의를 살펴보면,\n\\[\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\]\n\\[\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\]\n라고 볼 수 있다. 이를 이용하여 근사계산하면\n\ndef l(w0,w1):\n    return torch.sum((y-w0-w1*x)**2)\n\n\nl(-5,10), loss # 로스값일치\n\n(tensor(8587.6240), tensor(8587.6240, grad_fn=&lt;SumBackward0&gt;))\n\n\n\nh=0.001 \n(l(-5+h,10) - l(-5,10))/h\n\ntensor(-1342.7733)\n\n\n\nh=0.001 \n(l(-5,10+h) - l(-5,10))/h\n\ntensor(1189.4531)\n\n\n이 값은 What.grad에 저장된 값과 거의 비슷하다.\n\nWhat.grad\n\ntensor([[-1342.2465],\n        [ 1188.9203]])\n\n\n- 이제 아래의 공식에 넣고 업데이트해보자\n\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\]\n\nalpha = 0.001 \nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.linalg.inv((X.T @ X)) @ X.T @ y} -- 회귀분석으로 구한값\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값(이건 비밀~~)\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3422],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6578],\n        [ 8.8111]]) -- 수정후\ntensor([[2.4459],\n        [4.0043]]) -- 회귀분석으로 구한값\ntensor([[2.5000],\n        [4.0000]]) -- 참값(이건 비밀~~)\n\n\n\nalpha를 잘 잡아야함~\n\n- 1회 수정결과를 시각화\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6578],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()"
  },
  {
    "objectID": "posts/02wk-1.html#d.-3단계-iteration-learn-estimate-bfhat-w",
    "href": "posts/02wk-1.html#d.-3단계-iteration-learn-estimate-bfhat-w",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "D. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o', label = \"ovserved data\")\nplt.plot(x,X@What.data,'--', label = r\"$\\hat{\\bf y}={\\bf X}@\\hat{\\bf W}$ after 30 iterations (=epochs)\")\nplt.legend()"
  },
  {
    "objectID": "posts/02wk-1.html#a.-단순무식한-print",
    "href": "posts/02wk-1.html#a.-단순무식한-print",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 단순무식한 print",
    "text": "A. 단순무식한 print\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    print(f'loss = {loss:.2f} \\t 업데이트폭 = {-0.001 * What.grad.reshape(-1)} \\t 업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.62   업데이트폭 = tensor([ 1.3422, -1.1889])      업데이트결과: tensor([-3.6578,  8.8111])\nloss = 5675.18   업데이트폭 = tensor([ 1.1029, -0.9499])      업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.63   업데이트폭 = tensor([ 0.9056, -0.7596])      업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58   업데이트폭 = tensor([ 0.7431, -0.6081])      업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04   업데이트폭 = tensor([ 0.6094, -0.4872])      업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.33   업데이트폭 = tensor([ 0.4995, -0.3907])      업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.85    업데이트폭 = tensor([ 0.4091, -0.3136])      업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97    업데이트폭 = tensor([ 0.3350, -0.2519])      업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.72    업데이트폭 = tensor([ 0.2742, -0.2025])      업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40    업데이트폭 = tensor([ 0.2243, -0.1629])      업데이트결과: tensor([1.4453, 4.6848])\nloss = 162.73    업데이트폭 = tensor([ 0.1834, -0.1311])      업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.64    업데이트폭 = tensor([ 0.1500, -0.1056])      업데이트결과: tensor([1.7787, 4.4481])\nloss = 86.13     업데이트폭 = tensor([ 0.1226, -0.0851])      업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.94     업데이트폭 = tensor([ 0.1001, -0.0687])      업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57     업데이트폭 = tensor([ 0.0818, -0.0554])      업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72     업데이트폭 = tensor([ 0.0668, -0.0447])      업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86     업데이트폭 = tensor([ 0.0545, -0.0361])      업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.98     업데이트폭 = tensor([ 0.0445, -0.0292])      업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.41     업데이트폭 = tensor([ 0.0363, -0.0236])      업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70     업데이트폭 = tensor([ 0.0296, -0.0191])      업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.58     업데이트폭 = tensor([ 0.0242, -0.0155])      업데이트결과: tensor([2.3391, 4.0705])\nloss = 27.83     업데이트폭 = tensor([ 0.0197, -0.0125])      업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33     업데이트폭 = tensor([ 0.0161, -0.0101])      업데이트결과: tensor([2.3749, 4.0479])\nloss = 27.01     업데이트폭 = tensor([ 0.0131, -0.0082])      업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79     업데이트폭 = tensor([ 0.0107, -0.0067])      업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.65     업데이트폭 = tensor([ 0.0087, -0.0054])      업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55     업데이트폭 = tensor([ 0.0071, -0.0044])      업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.49     업데이트폭 = tensor([ 0.0058, -0.0035])      업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.45     업데이트폭 = tensor([ 0.0047, -0.0029])      업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.42     업데이트폭 = tensor([ 0.0038, -0.0023])      업데이트결과: tensor([2.4289, 4.0145])"
  },
  {
    "objectID": "posts/02wk-1.html#b.-반복시각화-yhat의-관점에서",
    "href": "posts/02wk-1.html#b.-반복시각화-yhat의-관점에서",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 반복시각화 – yhat의 관점에서!",
    "text": "B. 반복시각화 – yhat의 관점에서!\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfig = plt.plot(x,y,'o',label = \"observed\")\nplt.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    plt.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None"
  },
  {
    "objectID": "posts/02wk-1.html#c.-반복시각화-loss의-관점에서",
    "href": "posts/02wk-1.html#c.-반복시각화-loss의-관점에서",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 반복시각화 – loss의 관점에서!!",
    "text": "C. 반복시각화 – loss의 관점에서!!\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    return fig\n\n\nl(-5,10)\n\ntensor(8587.6240)\n\n\n\nfig = plot_loss()\n\n\n\n\n\n\n\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\n\n\n\n\n\n\n\n\n\nw0,w1 = What.data.reshape(-1)\n\n\nWhat.data\n\ntensor([[2.4289],\n        [4.0145]])\n\n\n\nw0,w1\n\n(tensor(2.4289), tensor(4.0145))\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    w0,w1 = What.data.reshape(-1) \n    ax.scatter(w0,w1,l(w0,w1),s=5,marker='o',color='blue')\n    What.grad = None\n\n\nfig"
  },
  {
    "objectID": "posts/02wk-1.html#d.-애니메이션",
    "href": "posts/02wk-1.html#d.-애니메이션",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 애니메이션",
    "text": "D. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nepoch = 0 부터 시작하여 시작점에서 출발하도록 애니메이션을 수정했습니당.\n\n\nani = show_animation(alpha=0.001)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-1.html#e.-학습률에-따른-시각화",
    "href": "posts/02wk-1.html#e.-학습률에-따른-시각화",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "E. 학습률에 따른 시각화",
    "text": "E. 학습률에 따른 시각화\n- \\(\\alpha\\)가 너무 작다면 비효율적임\n\nshow_animation(alpha=0.0001)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\)가 크다고 무조건 좋은건 또 아님\n\nshow_animation(alpha=0.0083)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 수틀리면 수렴안할수도??\n\nshow_animation(alpha=0.0085)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 그냥 망할수도??\n\nshow_animation(alpha=0.01)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-1.html#a.-해결하고-싶은것",
    "href": "posts/02wk-1.html#a.-해결하고-싶은것",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 해결하고 싶은것",
    "text": "A. 해결하고 싶은것\n아래와 같은 선형모형이 있다고 가정하자.\n\\[{\\bf y}={\\bf X}{\\boldsymbol \\beta} + {\\boldsymbol \\epsilon}\\]\n이러한 모형에 대하여 아래와 같이 손실함수를 정의하자.\n\\[loss({\\boldsymbol \\beta}) = ({\\bf y} - {\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y} - {\\bf X}{\\boldsymbol \\beta}) \\]\n이때 손실함수의 미분값을 아래와 같이 주어지고,\n\\[\\frac{\\partial}{\\partial {\\boldsymbol \\beta}}loss({\\boldsymbol \\beta}) = -2{\\bf X}^\\top{\\bf y}+2{\\bf X}^\\top{\\bf X}{\\boldsymbol \\beta}\\]\n따라서 손실함수를 최소화하는 추정량이 아래와 같이 주어짐을 보여라.\n\\[\\hat{\\boldsymbol \\beta} = ({\\bf X}^\\top {\\bf X})^{-1}{\\bf X}^\\top{\\bf y}\\]"
  },
  {
    "objectID": "posts/02wk-1.html#b.-해설강의-및-보충자료",
    "href": "posts/02wk-1.html#b.-해설강의-및-보충자료",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 해설강의 및 보충자료",
    "text": "B. 해설강의 및 보충자료\n\nhttps://github.com/guebin/DL2024/blob/main/posts/02wksupp.pdf"
  },
  {
    "objectID": "posts/05wk-1.html#a.-gpu-사용방법",
    "href": "posts/05wk-1.html#a.-gpu-사용방법",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. GPU 사용방법",
    "text": "A. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\n!nvidia-smi # before\n\nMon Apr  1 16:42:53 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   35C    P8              34W / 420W |     26MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1130      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1209      G   /usr/bin/gnome-shell                          8MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n\n!nvidia-smi\n\nMon Apr  1 16:42:53 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   37C    P2              39W / 420W |    287MiB / 24576MiB |      2%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1130      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1209      G   /usr/bin/gnome-shell                          8MiB |\n|    0   N/A  N/A    362478      C   ...b3/anaconda3/envs/dl2024/bin/python      256MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\nGPU에 메모리를 올리면 GPU메모리가 점유된다! (26MiB -&gt; 287MiB)\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n\n\n\n\n\n강의중 net을 재선언한 이유\n\n\n\n- 아래와 같이 x_cpu 혹은 y_cpu에 .to(\"cuda:0\")메소드를 쓸 경우\nx_cpu.to(\"cuda:0\")\ny_cpu.to(\"cuda:0\")\nx_cpu와 y_cpu는 cpu에 그대로 있음.\n- 그런데 아래와 같이 net_cpu에서 .to(\"cuda:0\")메소드를 쓸 경우\nnet_cpu.to(\"cuda:0\")\nnet_cpu 자체가 gpu에 올라가게 됨.\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/05wk-1.html#b.-시간측정-예비학습",
    "href": "posts/05wk-1.html#b.-시간측정-예비학습",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. 시간측정 (예비학습)",
    "text": "B. 시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n1.2487025260925293"
  },
  {
    "objectID": "posts/05wk-1.html#c.-cpu-vs-gpu-512-nodes",
    "href": "posts/05wk-1.html#c.-cpu-vs-gpu-512-nodes",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. CPU vs GPU (512 nodes)",
    "text": "C. CPU vs GPU (512 nodes)\n- CPU (512 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.35651373863220215\n\n\n- GPU (512 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5209517478942871\n\n\n\nCPU가 더 빠르다??"
  },
  {
    "objectID": "posts/05wk-1.html#d.-cpu-vs-gpu-20480-nodes",
    "href": "posts/05wk-1.html#d.-cpu-vs-gpu-20480-nodes",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. CPU vs GPU (20,480 nodes)",
    "text": "D. CPU vs GPU (20,480 nodes)\n- CPU (20,480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.7291958332061768\n\n\n- GPU (20,480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.4499187469482422\n\n\n\n왜 이런 차이가 나는가?\n연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/05wk-1.html#e.-cpu-vs-gpu-204800-nodes",
    "href": "posts/05wk-1.html#e.-cpu-vs-gpu-204800-nodes",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. CPU vs GPU (204,800 nodes)",
    "text": "E. CPU vs GPU (204,800 nodes)\n- CPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n85.68583369255066\n\n\n- GPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.3954846858978271"
  },
  {
    "objectID": "posts/05wk-1.html#a.-의문-좀-이상하지-않아요",
    "href": "posts/05wk-1.html#a.-의문-좀-이상하지-않아요",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. 의문: 좀 이상하지 않아요?",
    "text": "A. 의문: 좀 이상하지 않아요?\n- 국민상식: GPU 비싸요.. https://bbs.ruliweb.com/community/board/300143/read/61066881\n\nGPU 메모리 많아봐야 24GB, 그래도 비싸요.. http://shop.danawa.com/virtualestimate/?controller=estimateMain&methods=index&marketPlaceSeq=16\nGPU 메모리가 80GB일 경우 가격: https://prod.danawa.com/info/?pcode=21458333\n\n- 우리가 분석하는 데이터: 빅데이터..?\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 데이터의 크기가 커지는 순간 X.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸?\n- 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데?"
  },
  {
    "objectID": "posts/05wk-1.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/05wk-1.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요"
  },
  {
    "objectID": "posts/05wk-1.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/05wk-1.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-w_0-w_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-w_0-w_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-w_0-w_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-w_0-w_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n…"
  },
  {
    "objectID": "posts/05wk-1.html#d.-용어의-정리",
    "href": "posts/05wk-1.html#d.-용어의-정리",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. 용어의 정리",
    "text": "D. 용어의 정리\n옛날\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/05wk-1.html#e.-datasetds-dataloaderdl",
    "href": "posts/05wk-1.html#e.-datasetds-dataloaderdl",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. Dataset(ds), DataLoader(dl)",
    "text": "E. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 힘들것 같아요.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- ds: 섭스크립터블함\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n\nds=torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7fa66f6520d0&gt;\n\n\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n\n\n\n\n\n\nNote\n\n\n\n여기서 제가 __iter__ 가 숨겨져 있는 오브젝트일 경우만 for문이 동작한다고 설명 했는데요, __getitem__이 있는 경우도 동작한다고 합니다. 제가 잘못 알고 있었어요. 혼란을 드려 죄송합니다.\n\n그래도 dl은 for 를 돌리기위해서 만든 오브젝트라는 설명은 맞는 설명입니다.\nds역시 독특한 방식의 인덱싱을 지원하도록 한 오브젝트라는 설명도 맞는 설명입니다.\n\n\n\n- dl: 섭스크립터블하지 않지만 이터러블함\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3)\n#set(dir(dl)) & {'__iter__'}\n\n\nfor xi,yi in dl:\n    print(f\"x_batch:{xi.tolist()} \\t y_batch:{yi.tolist()}\")\n\nx_batch:[[0.0], [1.0], [2.0]]    y_batch:[[1.0], [1.0], [1.0]]\nx_batch:[[3.0], [4.0], [5.0]]    y_batch:[[1.0], [1.0], [0.0]]\nx_batch:[[6.0], [7.0], [8.0]]    y_batch:[[0.0], [0.0], [0.0]]\nx_batch:[[9.0]]      y_batch:[[0.0]]\n\n\n- 마지막관측치는 뭔데 단독으로 업데이트하냐?? –&gt; shuffle True 같이 자잘한 옵션도 있음..\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor xi,yi in dl:\n    print(f'x_batch={xi.tolist()} \\t y_batch={yi.tolist()}')\n\nx_batch=[[1.0], [8.0], [0.0]]    y_batch=[[1.0], [0.0], [1.0]]\nx_batch=[[2.0], [7.0], [6.0]]    y_batch=[[1.0], [0.0], [0.0]]\nx_batch=[[5.0], [3.0], [9.0]]    y_batch=[[0.0], [1.0], [0.0]]\nx_batch=[[4.0]]      y_batch=[[1.0]]"
  },
  {
    "objectID": "posts/05wk-1.html#f.-ds-dl을-이용한-mnist-구현",
    "href": "posts/05wk-1.html#f.-ds-dl을-이용한-mnist-구현",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "F. ds, dl을 이용한 MNIST 구현",
    "text": "F. ds, dl을 이용한 MNIST 구현\n- 목표: 확률적경사하강법과 그냥 경사하강법의 성능을 “동일 반복횟수”로 비교해보자.\n\nbatch_size = 2048로 설정할것\n\n- 그냥 경사하강법 – 미니배치 안쓰는 학습, 우리가 맨날하는 그거\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n## Step3: fit  \nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: Predict \n((yhat &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- “확률적”경사하강법 – 미니배치 쓰는 학습\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n# ## Step3: fit  \nfor epoc in range(100):\n    for xi,yi in dl:        \n        # step1 \n        #yihat = net(xi)\n        # step2 \n        loss = loss_fn(net(xi),yi)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n# ## Step4: Predict \n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9931)\n\n\n- GPU를 활용하는 “확률적”경사하강법 – 실제적으로는 이게 최종알고리즘\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n## Step3: fit  \nfor epoc in range(100):\n    for xi,yi in dl:        \n        # step1 \n        # step2 \n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n# ## Step4: Predict\nnet.to(\"cpu\")\n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9931)"
  },
  {
    "objectID": "posts/05wk-1.html#a.-결론-그냥-외우세요",
    "href": "posts/05wk-1.html#a.-결론-그냥-외우세요",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. 결론 (그냥 외우세요)",
    "text": "A. 결론 (그냥 외우세요)\n- 2개의 class를 구분하는 문제가 아니라 \\(k\\)개의 class를 구분해야 한다면?\n일반적인 개념\n\n손실함수: BCE loss \\(\\to\\) Cross Entropy loss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: sig \\(\\to\\) softmax\n\n파이토치 한정\n\ny의형태: (n,) vector + int형 // (n,k) one-hot encoded matrix + float형\n손실함수: torch.nn.BCEWithLogitsLoss, \\(\\to\\) torch.nn.CrossEntropyLoss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: None \\(\\to\\) None (손실함수에 이미 마지막층의 활성화가 포함)"
  },
  {
    "objectID": "posts/05wk-1.html#b.-실습-3개의-클래스를-구분",
    "href": "posts/05wk-1.html#b.-실습-3개의-클래스를-구분",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. 실습: 3개의 클래스를 구분",
    "text": "B. 실습: 3개의 클래스를 구분\n- 정리된 코드1: 통계잘하는데 파이토치 못쓰는 사람의 코드\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\ny = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    \n## Step4: 적합 (혹은 적합결과확인)\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9827)\n\n\n- 정리된 코드2: 파이토치를 잘하는 사람의 코드\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\n#y = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: 적합 (혹은 적합결과확인)    \n(netout.argmax(axis=1) == y).float().mean()\n\ntensor(0.9827)\n\n\n\n완전같은코드임"
  },
  {
    "objectID": "posts/05wk-1.html#c.-softmax",
    "href": "posts/05wk-1.html#c.-softmax",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. Softmax",
    "text": "C. Softmax\n- 눈치: softmax를 쓰기 직전의 숫자들은 (n,k)꼴로 되어있음. 각 observation 마다 k개의 숫자가 있는데, 그중에서 유난히 큰 하나의 숫자가 있음.\n\nnet(X)\n\ntensor([[ 4.4836, -4.5924, -3.4632],\n        [ 1.9839, -3.4456,  0.3030],\n        [ 5.9082, -7.5250, -0.7634],\n        ...,\n        [-0.8089, -0.8294,  0.6012],\n        [-2.1901, -0.4458,  0.7465],\n        [-1.6856, -2.2825,  5.1892]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\ny\n\ntensor([0, 0, 0,  ..., 2, 2, 2])\n\n\n- 수식\n\n\\(\\text{sig}(u)=\\frac{e^u}{1+e^u}\\)\n\\(\\text{softmax}({\\boldsymbol u})=\\text{softmax}([u_1,u_2,\\dots,u_k])=\\big[ \\frac{e^{u_1}}{e^{u_1}+\\dots e^{u_k}},\\dots,\\frac{e^{u_k}}{e^{u_1}+\\dots e^{u_k}}\\big]\\)\n\n- torch.nn.Softmax() 손계산\n(예시1) – 잘못계산\n\nsoftmax = torch.nn.Softmax(dim=0)\n\n\nnetout = torch.tensor([[-2.0,-2.0,0.0],\n                        [3.14,3.14,3.14],\n                        [0.0,0.0,2.0],\n                        [2.0,2.0,4.0],\n                        [0.0,0.0,0.0]])\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout) \n\ntensor([[0.0041, 0.0041, 0.0115],\n        [0.7081, 0.7081, 0.2653],\n        [0.0306, 0.0306, 0.0848],\n        [0.2265, 0.2265, 0.6269],\n        [0.0306, 0.0306, 0.0115]])\n\n\n(예시2) – 이게 맞게 계산되는 것임\n\nsoftmax = torch.nn.Softmax(dim=1)\n\n\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout)\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시3) – 차원을 명시안하면 맞게 계산해주고 경고 줌\n\nsoftmax = torch.nn.Softmax()\n\n\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout)\n\n/home/cgb3/anaconda3/envs/dl2024/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시4) – 진짜 손계산\n\nnetout \n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\ntorch.exp(netout)\n\ntensor([[ 0.1353,  0.1353,  1.0000],\n        [23.1039, 23.1039, 23.1039],\n        [ 1.0000,  1.0000,  7.3891],\n        [ 7.3891,  7.3891, 54.5981],\n        [ 1.0000,  1.0000,  1.0000]])\n\n\n\n0.1353/(0.1353 + 0.1353 + 1.0000), 0.1353/(0.1353 + 0.1353 + 1.0000), 1.0000/(0.1353 + 0.1353 + 1.0000) # 첫 obs\n\n(0.10648512513773022, 0.10648512513773022, 0.7870297497245397)\n\n\n\ntorch.exp(netout[1])/torch.exp(netout[1]).sum() # 두번째 obs \n\ntensor([0.3333, 0.3333, 0.3333])"
  },
  {
    "objectID": "posts/05wk-1.html#d.-crossentropyloss",
    "href": "posts/05wk-1.html#d.-crossentropyloss",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. CrossEntropyLoss",
    "text": "D. CrossEntropyLoss\n- 수식\n# 2개의 카테고리\n- 예제1: BCELoss vs BCEWithLogisticLoss\n\ny = torch.tensor([0,0,1]).reshape(-1,1).float()\nnetout = torch.tensor([-1, 0, 1]).reshape(-1,1).float()\ny,netout\n\n(tensor([[0.],\n         [0.],\n         [1.]]),\n tensor([[-1.],\n         [ 0.],\n         [ 1.]]))\n\n\n\n# 계산방법1: 공식암기\nsig = torch.nn.Sigmoid()\nyhat = sig(netout)\n- torch.sum(torch.log(yhat)*y + torch.log(1-yhat)*(1-y))/3\n\ntensor(0.4399)\n\n\n\n# 계산방법2: torch.nn.BCELoss() 이용\nsig = torch.nn.Sigmoid()\nyhat = sig(netout)\nloss_fn = torch.nn.BCELoss()\nloss_fn(yhat,y)\n\ntensor(0.4399)\n\n\n\n# 계산방법3: torch.nn.BCEWithLogitsLoss() 이용\nloss_fn = torch.nn.BCEWithLogitsLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n- 예제2: BCEWithLogisticLoss vs CrossEntropyLoss\n\ntorch.concat([sig(netout),1-sig(netout)],axis=1)\n\ntensor([[0.2689, 0.7311],\n        [0.5000, 0.5000],\n        [0.7311, 0.2689]])\n\n\n\nnetout = torch.tensor([[3,2],[2,2],[5,6]]).float()\ny = torch.tensor([[1,0],[1,0],[0,1]]).float()\ny,netout #,netout[:,[1]]-netout[:,[0]]\n\n(tensor([[1., 0.],\n         [1., 0.],\n         [0., 1.]]),\n tensor([[3., 2.],\n         [2., 2.],\n         [5., 6.]]))\n\n\n\nsoftmax(netout)\n\ntensor([[0.7311, 0.2689],\n        [0.5000, 0.5000],\n        [0.2689, 0.7311]])\n\n\n\n# 계산방법1: 공식암기\n-torch.sum(torch.log(softmax(netout))*y)/3\n\ntensor(0.4399)\n\n\n\n# 계산방법2: torch.nn.CrossEntropyLoss() 이용 + y는 one-hot으로 정리\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n\n# 계산방법3: torch.nn.CrossEntropyLoss() 이용 + y는 0,1 로 정리\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n#\n# 3개의 카테고리\n\ny = torch.tensor([2,1,2,2,0])\ny_onehot = torch.nn.functional.one_hot(y)\nnetout = torch.tensor(\n    [[-2.0000, -2.0000,  0.0000],\n     [ 3.1400,  3.1400,  3.1400],\n     [ 0.0000,  0.0000,  2.0000],\n     [ 2.0000,  2.0000,  4.0000],\n     [ 0.0000,  0.0000,  0.0000]]\n)\ny,y_onehot\n\n(tensor([2, 1, 2, 2, 0]),\n tensor([[0, 0, 1],\n         [0, 1, 0],\n         [0, 0, 1],\n         [0, 0, 1],\n         [1, 0, 0]]))\n\n\n\n## 방법1 -- 추천X\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y_onehot.float())\n\ntensor(0.5832)\n\n\n\n## 방법2 -- 추천O\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.5832)\n\n\n\n## 방법3 -- 공식.. (이걸 쓰는사람은 없겠지?)\nsoftmax = torch.nn.Softmax() \nloss_fn = torch.nn.CrossEntropyLoss()\n- torch.sum(torch.log(softmax(netout))*y_onehot)/5\n\ntensor(0.5832)\n\n\n#\n- 계산하는 공식을 아는것도 중요한데 torch.nn.CrossEntropyLoss() 에는 softmax 활성화함수가 이미 포함되어 있다는 것을 확인하는 것이 더 중요함.\n- torch.nn.CrossEntropyLoss() 는 사실 torch.nn.CEWithSoftmaxLoss() 정도로 바꾸는 것이 더 말이 되는 것 같다."
  },
  {
    "objectID": "posts/05wk-1.html#e.-minor-topic-이진분류와-crossentropy",
    "href": "posts/05wk-1.html#e.-minor-topic-이진분류와-crossentropy",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. Minor Topic: 이진분류와 CrossEntropy",
    "text": "E. Minor Topic: 이진분류와 CrossEntropy\n- 2개의 클래스일경우에도 CrossEntropy를 쓸 수 있지 않을까?\n\n## Step1: 데이터준비 \npath = untar_data(URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1]).reshape(-1,1*28*28)/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: fit  \nfor epoc in range(70): \n    ## 1 \n    ## 2 \n    loss= loss_fn(net(X),y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n## Step4: Predict \nsoftmax = torch.nn.Softmax()\n(net(X).argmax(axis=1) == y).float().mean()\n\ntensor(0.9983)\n\n\n- 이진분류문제 = “y=0 or y=1” 을 맞추는 문제 = 성공과 실패를 맞추는 문제 = 성공확률과 실패확률을 추정하는 문제\n- softmax, sigmoid\n\nsoftmax: (실패확률, 성공확률) 꼴로 결과가 나옴 // softmax는 실패확률과 성공확률을 둘다 추정한다.\nsigmoid: (성공확률) 꼴로 결과가 나옴 // sigmoid는 성공확률만 추정한다.\n\n- 그런데 “실패확률=1-성공확률” 이므로 사실상 둘은 같은걸 추정하는 셈이다. (성공확률만 추정하면 실패확률은 저절로 추정되니까)\n- 즉 아래는 같은 표현력을 가진 모형이다.\n\n\n- 둘은 같은 표현력을 가진 모형인데 학습할 파라메터는 sigmoid의 경우가 더 적다. \\(\\to\\) sigmoid를 사용하는 모형이 비용은 싸고 효과는 동일하다는 말 \\(\\to\\) 이진분류 한정해서는 softmax를 쓰지말고 sigmoid를 써야함.\n\nsoftmax가 갑자기 너무 안좋아보이는데 sigmoid는 k개의 클래스로 확장이 불가능한 반면 softmax는 확장이 용이하다는 장점이 있음."
  },
  {
    "objectID": "posts/05wk-1.html#f.-정리",
    "href": "posts/05wk-1.html#f.-정리",
    "title": "05wk-1: 깊은신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "F. 정리",
    "text": "F. 정리\n- 결론\n\n소프트맥스는 시그모이드의 확장이다.\n클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다.\n\n- 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (그냥 좀 비효율적인 느낌이 드는 것 뿐임. 흑백이미지를 칼라잉크로 출력하는 느낌)\n참고\n\n\n\n\\(y\\)\n분포가정\n마지막층의 활성화함수\n손실함수\n\n\n\n\n3.45, 4.43, … (연속형)\n정규분포\nNone (or Identity)\nMSE\n\n\n0 or 1\n이항분포 with \\(n=1\\) (=베르누이)\nSigmoid\nBCE\n\n\n[0,0,1], [0,1,0], [1,0,0]\n다항분포 with \\(n=1\\)\nSoftmax\nCross Entropy"
  },
  {
    "objectID": "posts/03wk-2.html#a.-방법1",
    "href": "posts/03wk-2.html#a.-방법1",
    "title": "03wk-2: 깊은신경망 (1) – 로지스틱의 한계 극복",
    "section": "A. 방법1",
    "text": "A. 방법1\n\ny = x*0 \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\n\n\nplt.plot(y,'--')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n강의영상에 보셨듯이 아래의 코드실행결과는 다르게 나옵니다.\n## 아래를 실행하면 꺽인선이 나오는데용...\nx = torch.linspace(-1,1,1001).reshape(-1,1)\ny = x*0 + x \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n## 이걸 실행하면 그냥 직선이 나옵니다...\nx = torch.linspace(-1,1,1001).reshape(-1,1)\ny = x \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n다르게 나오는 이유가 너무 궁금하시다면 아래의 링크로 가셔서 깊은복사/얕은복사에 대한 개념을 이해하시면 됩니다. (그렇지만 가능하다면 궁금해하지 마세요…..)\n\n깊은복사 얕은복사 강의들으러 가기"
  },
  {
    "objectID": "posts/03wk-2.html#b.-방법2-렐루이용",
    "href": "posts/03wk-2.html#b.-방법2-렐루이용",
    "title": "03wk-2: 깊은신경망 (1) – 로지스틱의 한계 극복",
    "section": "B. 방법2 – 렐루이용",
    "text": "B. 방법2 – 렐루이용\n\nrelu = torch.nn.ReLU()\n\n\nplt.plot(relu(x),'--',label=r'$relu(x)$')\nplt.plot(relu(-x),'--',label=r'$relu(-x)$')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(-4.5*relu(x),'--',label=r'$-4.5\\times relu(x) + 4.5$')\nplt.plot(-9*relu(-x),'--',label=r'$-9\\times relu(-x) + 4.5$')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(-4.5*relu(x)-9*relu(-x),'--',label=r'$-4.5\\times relu(x) -9 \\times relu(-x)$')\nplt.plot(y,'--',label=r'$y$')\nplt.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',label=r'$-4.5\\times relu(x) -9 \\times relu(-x)+4.5$')\nplt.legend()\n\n\n\n\n\n\n\n\n- 우리의 목표: 저 초록선에서 시그모이드를 태우면된다. 즉 아래의 느낌임\n\nsig = torch.nn.Sigmoid()\n\n\nfig = plt.figure(figsize=(8, 4))\nspec = fig.add_gridspec(4, 4)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\nax6 = fig.add_subplot(spec[1:3,3]); ax6.set_title('sig(...)');\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nax6.plot(sig(-4.5*relu(x)-9*relu(-x)+4.5),'--',color='C2')\nfig.tight_layout()"
  },
  {
    "objectID": "posts/03wk-2.html#c.-방법2의-다른구현",
    "href": "posts/03wk-2.html#c.-방법2의-다른구현",
    "title": "03wk-2: 깊은신경망 (1) – 로지스틱의 한계 극복",
    "section": "C. 방법2의 다른구현",
    "text": "C. 방법2의 다른구현\n- 렐루이용하여 만드는 방법 정리\n\n벡터 x와 relu함수를 준비한다.\nu = [x,-x] 를 계산한다.\nv = [relu(x), relu(-x)] 를 계산한다.\ny = -4.5 * relu(x) + 9 * relu(-x) +4.5 를 계산한다.\n\n- 1단계\n\nx,relu\n\n(tensor([[-1.0000],\n         [-0.9980],\n         [-0.9960],\n         ...,\n         [ 0.9960],\n         [ 0.9980],\n         [ 1.0000]]),\n ReLU())\n\n\n- 2단계\n\nu = torch.concat([x,-x],axis=1) # u = [x, -x] 같은것\nu\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]])\n\n\n- 3단계\n\nv = relu(u) # 각각의 column에 렐루취함\nv\n\ntensor([[0.0000, 1.0000],\n        [0.0000, 0.9980],\n        [0.0000, 0.9960],\n        ...,\n        [0.9960, 0.0000],\n        [0.9980, 0.0000],\n        [1.0000, 0.0000]])\n\n\n- 4단계\n\n-4.5 * v[:,[0]] - 9.0 * v[:,[1]] +4.5\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n\ny\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n- 그런데, 4단계는 아래와 같이 볼 수 있다.\n\n\\({\\boldsymbol v}\\begin{bmatrix} -4.5 \\\\ -9.0 \\end{bmatrix} + 4.5 = \\begin{bmatrix} v_{11} & v_{12} \\\\ v_{21} & v_{22} \\\\ \\dots & \\dots \\\\ v_{n1} & v_{n2} \\\\ \\end{bmatrix}\\begin{bmatrix} -4.5 \\\\ -9.0 \\end{bmatrix} + 4.5 = \\begin{bmatrix} -4.5 v_{11} - 9.0 v_{12} + 4.5 \\\\ -4.5 v_{21} - 9.0 v_{22} + 4.5 \\\\ \\dots \\\\ -4.5 v_{n1} - 9.0 v_{n2} + 4.5 \\\\ \\end{bmatrix}\\)\n\n위의 수식을 참고하여 매트릭스의 곱 형태로 다시 포현하면 아래와 같다.\n\n#-4.5 * v[:,[0]] - 9.0 * v[:,[1]] +4.5\nWhat = torch.tensor([[-4.5],[-9.0]]) \nv @ What + 4.5 \n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n이제 매트릭스의 곱 대신에 torch.nn.Linear()를 이용하면 아래의 코드와 같아진다.\n\nl2 = torch.nn.Linear(\n    in_features=2,\n    out_features=1 \n)\n\n\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nl2(v)\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 사실 2단계도 아래와 같이 볼 수 있다.\n\\[\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\dots \\\\\nx_n\n\\end{bmatrix}\\begin{bmatrix} 1 & -1 \\end{bmatrix} = \\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n \\end{bmatrix}\\]\n\n#u = torch.concat([x,-x],axis=1) # u1 = [x, -x] 같은것\n\n\nl1 = torch.nn.Linear(1,2)\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\n\n\nl1(x)\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 따라서 torch.nn 에 포함된 레이어를 이용하면 아래와 같이 표현할 할 수 있다.\n\nl1 = torch.nn.Linear(1,2)\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\na1 = torch.nn.ReLU()\nl2 = torch.nn.Linear(2,1)\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nl2(a1(l1(x))), y\n\n(tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]]))\n\n\n- 각각의 layer를 torch.nn.Sequential() 로 묶으면 아래와 같이 정리할 수 있다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1)\n)\nl1,a1,l2 = net\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nnet(x),y\n\n(tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]]))"
  },
  {
    "objectID": "posts/03wk-2.html#d.-수식표현",
    "href": "posts/03wk-2.html#d.-수식표현",
    "title": "03wk-2: 깊은신경망 (1) – 로지스틱의 한계 극복",
    "section": "D. 수식표현",
    "text": "D. 수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(net({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/03wk-2.html#a.-데이터",
    "href": "posts/03wk-2.html#a.-데이터",
    "title": "03wk-2: 깊은신경망 (1) – 로지스틱의 한계 극복",
    "section": "A. 데이터",
    "text": "A. 데이터\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-2.html#b.-step-14",
    "href": "posts/03wk-2.html#b.-step-14",
    "title": "03wk-2: 깊은신경망 (1) – 로지스틱의 한계 극복",
    "section": "B. Step 1~4",
    "text": "B. Step 1~4\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- Step2,3,4 는 너무 뻔해서..\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 3000 epochs\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 6000 epochs\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#a.-step은-표현-불가능하지-않나",
    "href": "posts/04wk-1.html#a.-step은-표현-불가능하지-않나",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. Step은 표현 불가능하지 않나?",
    "text": "A. Step은 표현 불가능하지 않나?\n- 맞춰봐\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\n#plt.plot(u,alpha=0.2)\nplt.plot(x,y,'.',alpha=0.01,color=\"C0\")\nplt.plot(x[0],y[0],'o',color=\"C0\",label=r\"observed data (with error): $(x_i,y_i)$\")\nplt.plot(x,v,'--',label=r\"prob (true, unknown): $(x_i,\\pi_i)$ or $(x_i,v_i)$\",color=\"C1\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 저 주황색 구조를 어떻게 표현하지? \\(\\to\\) 선이 많이 꺽이면되는거아냐?\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,256)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,256)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,1),\n    #torch.nn.Sigmoid()\n)\n#loss_fn = torch.nn.BCELoss()\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nfig,ax = plt.subplots(1,2)\nax[0].plot(x,u,'--',label=r\"$(x_i,u_i)$\")\nax[0].plot(x,yhat.data,'--',label=r\"$(x_i,\\hat{u}_i)$\")\nax[0].legend()\nax[0].set_title(\"before sig\")\nax[1].plot(x,y,'.',alpha=0.02,color=\"blue\")\nax[1].plot(x,v,'--', color=\"C0\", label=r\"$(x_i,v_i)$ or $(x_i,\\pi_i)$\")\nax[1].plot(x,sig(yhat.data),'--',color=\"C1\",label=r\"$(x_i,\\hat{v}_i)$ or $(x_i,\\hat{\\pi}_i)$\")\nax[1].legend()\nax[1].set_title(\"after sig\")\n\nText(0.5, 1.0, 'after sig')"
  },
  {
    "objectID": "posts/04wk-1.html#b.-곡선은-표현-불가능하지-않나",
    "href": "posts/04wk-1.html#b.-곡선은-표현-불가능하지-않나",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 곡선은 표현 불가능하지 않나?",
    "text": "B. 곡선은 표현 불가능하지 않나?\n- 맞춰봐1\n1 2024년 수능 미적30번 문제에 나온 함수응용\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=r\"observed data (with error): $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unknown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 맞춰본다..\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1024)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,1024)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1024),\n    torch.nn.ReLU(),\n    torch.nn.Linear(1024,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=r\"observed data: $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unkown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.plot(x,yhat.data,'--',color=\"C1\",label=r\"underlying (esimated): $(x_i,\\hat{y}_i)$\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#a.-시벤코의-정리-소개",
    "href": "posts/04wk-1.html#a.-시벤코의-정리-소개",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 시벤코의 정리 소개",
    "text": "A. 시벤코의 정리 소개\n\n\n\n\n\n\nUniversal Approximation Thm (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 continuous mapping\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 심층신경망(DNN)이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 심층신경망은 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}\\)는 토익점수, GPA, 공모전참가여부, \\({\\bf y}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 심층신경망은 항상 찾을 수 있다.\n\\({\\bf X}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 \\({\\bf y}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 심층신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 심층신경망 모델의 표현력은 무한대라 볼 수 있다.\n\n\n\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/04wk-1.html#b.-왜-가능한가",
    "href": "posts/04wk-1.html#b.-왜-가능한가",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 왜 가능한가?",
    "text": "B. 왜 가능한가?\n- 데이터\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\n\n- 아래와 같은 네트워크를 고려하자. (스펙올라도 취업못하는 예제에서 썼던 네크워크랑 비슷해요)\n\nl1 = torch.nn.Linear(in_features=1,out_features=2)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=2,out_features=1)\n\n- 직관1: \\(l_1\\),\\(l_2\\)의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n\n\n\n\n\n\n\n- 직관2: 아래들도 가능할듯?\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n- 직관3: 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 주황색선 + 파란색선도 가능할 것 같다. \\(\\to\\) 실제로 가능함\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n\n이러한 함수는 계단모양이며, 0을 제외한 서로다른 계단의 높이는 2개가 된다. 이를 간단히 “2단계-계단함수”라고 칭하자.\n\n- 정리1: 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 “1단계-계단함수” 함수 \\(h\\)를 만들 수 있다.\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 활성화함수로 하고 \\(m\\)개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 “m단계-계단함수”와 같은 형태의 네트워크는 아래와 같이 \\(m\\)개의 은닉노드를 써서 항상 표현할 수 있다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- 직관4: 그런데 어떠한 함수형태라도 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않나?"
  },
  {
    "objectID": "posts/04wk-1.html#c.-h의-위력",
    "href": "posts/04wk-1.html#c.-h의-위력",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. \\(h\\)의 위력",
    "text": "C. \\(h\\)의 위력\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v # activation 의 출력\n\n\na1 = MyActivation()\n# a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()\n\n- 아래와 같이 하나의 은닉층을 가지고 있더라도 많은 노드수만 보장되면 매우 충분한 표현력을 가짐\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- \\(h\\)의 위력\n예제1 – 스펙높아도 취업이 안된다고??\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\ntorch.manual_seed(43052)\nclass MyActivation(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2, label=\"observed data (with error)\")\nplt.plot(x,prob,'--', label=\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated)\")\nplt.legend()\n\n\n\n\n\n\n\n\n예제2 – 수능에 나왔다던 이상한 곡선..?\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\ntorch.manual_seed(43052)\nclass MyActivation(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,alpha=0.2,label=\"observed data (with error)\")\nplt.plot(x,fx,'--',label=\"underlying (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"underlying (estimated)\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#d.-의문점",
    "href": "posts/04wk-1.html#d.-의문점",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 의문점",
    "text": "D. 의문점\n- 이 수업을 잘 이해한 사람: 그냥 활성화함수를 \\(h\\)로 쓰면 끝 아니야? 뭐하러 relu 를 쓰는거지?\n- 딥러닝을 좀 공부해본사람1: 왜 딥러닝이 2010년이 지나서야 떳지? 1989년에 세상의 모든 문제가 풀려야 하는것 아닌가?\n- 딥러닝을 좀 공부해본사람2: 하나의 은닉층을 표현하는 네크워크는 잘 안쓰지 않나? 은닉층이 많을수록 좋다고 들었는데?\n- 약간의 의구심이 있지만 아무튼 우리는 아래의 무기를 가진 꼴이 되었다.\n\n\n\n\n\n\n우리의 무기\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크로,\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n\\(f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\) 인 모든 continuous mapping \\(f\\) 을 원하는 정확도로 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/04wk-1.html#a.-데이터-다운로드",
    "href": "posts/04wk-1.html#a.-데이터-다운로드",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 데이터 다운로드",
    "text": "A. 데이터 다운로드\n\nfrom fastai.data.all import *\n\n\nuntar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:00&lt;00:00]\n    \n    \n\n\nPath('/root/.fastai/data/mnist_png')\n\n\n\n!ls '/root/.fastai/data/mnist_png'\n\ntesting  training\n\n\n\n!ls '/root/.fastai/data/mnist_png/training/'\n\n0  1  2  3  4  5  6  7  8  9\n\n\n\n!ls '/root/.fastai/data/mnist_png/training/3' | head\n\n10000.png\n10011.png\n10031.png\n10034.png\n10042.png\n10052.png\n10074.png\n1007.png\n10091.png\n10093.png\n\n\n\nimport torchvision\n\n\nimg3 = torchvision.io.read_image('/root/.fastai/data/mnist_png/training/3/10.png')\nplt.imshow(img3.reshape(28,28),cmap=\"gray\")"
  },
  {
    "objectID": "posts/04wk-1.html#b.-예비학습-plt.imshow",
    "href": "posts/04wk-1.html#b.-예비학습-plt.imshow",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 예비학습 – `plt.imshow()",
    "text": "B. 예비학습 – `plt.imshow()\n- plt.imshow(...) 에서 ...이 shape이 (??,??)이면 흑백이미지를 출력\n\nplt.imshow([[0,255],[0,255]],cmap='gray')\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n\nr = [[0,255],[0,255]]\ng = [[255,0],[0,0]]\nb = [[0,0],[255,0]]\nplt.imshow(np.stack([r,g,b],axis=2))\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n\nr = [[0,1],[0,1]]\ng = [[1,0],[0,0]]\nb = [[0,0],[1,0]]\nplt.imshow(np.stack([r,g,b],axis=2))\n\n\n\n\n\n\n\n\n\nr = [[0,1.0],[0,1.0]]\ng = [[1.0,0],[0,0]]\nb = [[0,0],[1.0,0]]\nplt.imshow(np.stack([r,g,b],axis=2))"
  },
  {
    "objectID": "posts/04wk-1.html#c.-예비학습-pathlib",
    "href": "posts/04wk-1.html#c.-예비학습-pathlib",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. 예비학습 – pathlib",
    "text": "C. 예비학습 – pathlib\n\nimport pathlib\n\n- 오브젝트 생성\n\npath = pathlib.Path('.')\npath\n\nPath('.')\n\n\n- 기능1 – .ls()\n\npath.ls()\n\n(#2) [Path('.config'),Path('sample_data')]\n\n\n- 이미지 파일이 저장된 경로로 새로운 path오브젝트를 만들고 기능1 수행\n\npath = pathlib.Path('/root/.fastai/data/mnist_png')\npath\n\nPath('/root/.fastai/data/mnist_png')\n\n\n\npath.ls()\n\n(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]\n\n\n- 기능2: / 로 새로운 path 생성하기\n\n(path / 'training')\n\nPath('/root/.fastai/data/mnist_png/training')\n\n\n- 기능1,2의 결합\n\n(path / 'training').ls()\n\n(#10) [Path('/root/.fastai/data/mnist_png/training/6'),Path('/root/.fastai/data/mnist_png/training/9'),Path('/root/.fastai/data/mnist_png/training/8'),Path('/root/.fastai/data/mnist_png/training/7'),Path('/root/.fastai/data/mnist_png/training/5'),Path('/root/.fastai/data/mnist_png/training/4'),Path('/root/.fastai/data/mnist_png/training/0'),Path('/root/.fastai/data/mnist_png/training/1'),Path('/root/.fastai/data/mnist_png/training/2'),Path('/root/.fastai/data/mnist_png/training/3')]"
  },
  {
    "objectID": "posts/04wk-1.html#d.-데이터정리",
    "href": "posts/04wk-1.html#d.-데이터정리",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 데이터정리",
    "text": "D. 데이터정리\n- 데이터가 저장된 path 설정\n\npath = pathlib.Path('/root/.fastai/data/mnist_png')\n\n- X ,y를 만듦\n\nX3 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'training/3').ls()],axis=0)\nX7 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'training/7').ls()],axis=0)\n\n\nX3.shape, X7.shape\n\n(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))\n\n\n\ny = torch.tensor([0.0]*6131+[1.0]*6265).reshape(-1,1)\n\n\nX = torch.concat([X3,X7],axis=0)\nX.shape\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nplt.plot(y,'o')\n\n\n\n\n\n\n\n\n\n“y=0.0” 은 숫자3을 의미함, “y=1.0” 은 숫자7을 의미함\n숫자3은 6131개, 숫자7은 6265개 있음\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n\nX = torch.concat([X3,X7],axis=0).reshape(-1,28*28).float()\nX.shape, y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))"
  },
  {
    "objectID": "posts/04wk-1.html#e.-학습",
    "href": "posts/04wk-1.html#e.-학습",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "E. 학습",
    "text": "E. 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(200):\n    ## step1\n    yhat = net(X)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'o',label=r\"$(i,y_i)$ -- training data set\")\nplt.plot(net(X).data,'.',alpha=0.2, label=r\"$(i,\\hat{y}_i$ -- training data set\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n잘맞추는데?\n믿을수가 없는데..?\n\n\n((yhat.data &gt; 0.5) == y).float().mean() # train_accuracy\n\ntensor(0.9994)"
  },
  {
    "objectID": "posts/04wk-1.html#f.-test",
    "href": "posts/04wk-1.html#f.-test",
    "title": "04wk-1: 깊은신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "F. Test",
    "text": "F. Test\n\npath.ls()\n\n(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]\n\n\n\nXX3 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'testing/3').ls()],axis=0)\nXX7 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'testing/7').ls()],axis=0)\n\n\nXX3.shape,XX7.shape\n\n(torch.Size([1010, 1, 28, 28]), torch.Size([1028, 1, 28, 28]))\n\n\n\nXX = torch.concatenate([XX3,XX7],axis=0).reshape(-1,1*28*28).float()\nXX.shape\n\ntorch.Size([2038, 784])\n\n\n\nyy = torch.tensor([0]*1010 + [1]*1028).reshape(-1,1).float()\nyy.shape\n\ntorch.Size([2038, 1])\n\n\n\nplt.plot(yy,'o',label=r\"$(i,y_i)$ -- test data set\")\nplt.plot(net(XX).data,'.',label=r\"$(i,\\hat{y}_i)$ -- test data set\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n(yy == (net(XX)&gt;0.5)).float().mean() # test accuracy\n\ntensor(0.9897)\n\n\n\ntest 에서도 잘 맞춘다.."
  },
  {
    "objectID": "posts/01wk-2.html#a.-모형소개",
    "href": "posts/01wk-2.html#a.-모형소개",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "A. 모형소개",
    "text": "A. 모형소개\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "href": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "B. 회귀모형에서 데이터 생성",
    "text": "B. 회귀모형에서 데이터 생성\n\ntorch.manual_seed(43052)\nones= torch.ones(100).reshape(-1,1)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nW = torch.tensor([[2.5],[4]])\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#a.-손실함수",
    "href": "posts/01wk-2.html#a.-손실함수",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "A. 손실함수",
    "text": "A. 손실함수\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다.\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다.\n(중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (단계2에서 할일은 아님)\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법"
  },
  {
    "objectID": "posts/01wk-2.html#b.-경사하강법",
    "href": "posts/01wk-2.html#b.-경사하강법",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "B. 경사하강법",
    "text": "B. 경사하강법\n- 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(w \\leftarrow w - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n- 경사하강법 아이디어 (2차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n- 경사하강법 = loss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다."
  },
  {
    "objectID": "posts/06wk-1.html",
    "href": "posts/06wk-1.html",
    "title": "06wk-1: 합성곱신경망 (2)",
    "section": "",
    "text": "1. 강의영상\n\n#{{&lt;video https://youtu.be/playlist?list=PLQqh36zP38-wjNGgd4gmQJbQ66NLjUC2y&si=dusDZAwGOJS9TOKJ &gt;}}\n\n\n\n2. Imports\n\nimport torch\nimport matplotlib.pyplot as plt\nfrom fastai.data.all import *\nimport torchvision\n\n\n\nA3. DNN, ANN, MLP\n- DNN 은 깊은신경망, ANN 은 인공신경망, MLP 는 다층퍼셉트론이라 번역된다.\n- 아래의 네트워크는 ANN이라 볼 수 있다. 또한 레이어가 2개 있으므로 MLP라고 볼 수 있다. DNN 이라 보기는 애매하다. (그래서 이걸 얕은신경망(shallow network)이라고 표현하기도 합니다)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 아래의 네트워크는 ANN이라 볼 수 있다. 또한 레이어가 7개 있으므로 MLP라고 볼 수 있다. 이 정도면 깊어보이니까 DNN 이라 주장할 수 있어보인다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid(),    \n)\n- 아래의 네트워크는 ANN이라 볼 수 있다. 또한 레이어가 3개 있으므로 MLP라고 볼 수 있다. 이건 DNN이라고 봐야하나? 깊다기 보다는 넓은 신경망인데…\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1048576),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=1048576,out_features=1048576),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=1048576,out_features=1),\n    torch.nn.Sigmoid(),    \n)\n- 아래의 네트워크도 ANN이라 볼 수 있다.1 레이어는 2장이지만 MLP라고 부르진 않는다.\n1 그렇지만 이걸 ANN이라고 부르는 사람은 없는듯net = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)), # &lt;-- 학습할 파라메터\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1), # &lt;-- 학습할 파라메터\n    torch.nn.Sigmoid()\n)\n- 야매개념: 요즘은 거의 ANN \\(\\approx\\) MLP \\(\\approx\\) DNN 의 느낌으로 이해해도 무방함\n\n어지간한 모형은 다 ANN이라 우길 수 있다. 회귀분석도, 로지스틱분석도 마음먹으면 ANN으로 우길 수 있다. 그래서 “ANN을 썼다”라는건 엄청 모호한 말이다. 이런 이유로 사람들은 거의 MLP를 쓴 경우에 ANN을 썼다고 하고, 회귀모형을 쓴 경우에는 굳이 ANN을 썼다고 표현하지 않는다.\nMLP과 DNN은 구분이 모호하다. 하나이상의 은닉층만 포함하고 있으면 MLP라고 부를 수 있다. 적은 노드수를 유지하면서 은닉층을 여러개 쓰면 깊은 신경망이라고 하고, 많은 노드를 사용하면서 은닉층을 얇게, 그리고 노드를 많이 쓰면 넓은신경망이라고 한다. 노드수와 관계없이 층이 얇은 경우는 얕은신경망이라고 한다.2 즉 MLP의 모양에 따라서 “깊은신경망”, “얕은신경망”, “넓은신경망” 등의 용어를 사용한다.\n일반적으로 은닉층이 1개있으면 얕은신경망, 2개 이상이면 깊은신경망이라고 부른다고 합의되어있다. (은닉층이 2층까지 얕은신경망이라고 부르는 사람도 존재함) 얼마나 많은 노드부터 넓은신경망이라고 부르는지는 (제가 아는 한) 합의된바가 없다. 얼마나 깊을때 DNN으로 부를지 명확한 합의가 되어있지 않다. (3층-MLP부터 DNN으로 부르는 방식이 지지를 얻는듯. 그렇지만 4층-MLP 부터 DNN으로 부르는 사람도 존재함.)\nMLP의 정의가 가장 깔끔하다고 생각하지만 요즘 잘 쓰는 용어는 아니다. (MLP의 논문은 너무 예전임. 층을 세는것도 다름)\n제 결론: 따지고 보자면 DNN \\(\\subset\\) MLP \\(\\subset\\) ANN 이다. 그렇지만 MLP이지만 DNN은 아닌 네트워크를 지칭한다든가, ANN 이지만 MLP는 아닌 네트워크를 지칭하는 일은 흔하지 않으며, 지칭하더라도 부연설명을 친절하게 해준다. 따라서 부연설명 없이 ANN, MLP, DNN 을 지칭한다면 거의 DNN을 의미한다고 봐도 무방하다. 즉 ANN \\(\\approx\\) MLP \\(\\approx\\) DNN 라고 보면 된다. (엄밀하게는 틀린개념이죠)\n\n\n\n2 저는 이 표현 너무 싫어해요"
  },
  {
    "objectID": "posts/03wk-1.html#a.-로지스틱-모형",
    "href": "posts/03wk-1.html#a.-로지스틱-모형",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 로지스틱 모형",
    "text": "A. 로지스틱 모형\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) &lt;— 외우세요!!\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n1 원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/03wk-1.html#b.-데이터",
    "href": "posts/03wk-1.html#b.-데이터",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 데이터",
    "text": "B. 데이터\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0 = -1\nw1 = 5\nu = w0 + x*w1 # 선형변환이네?\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n우리의 목적: \\(x_i\\)가 들어가면 빨간곡선 \\(\\hat{y}_i\\)의 값을 만들어주는 mapping을 학습해보자."
  },
  {
    "objectID": "posts/03wk-1.html#c.-step1-net-설계-모델링",
    "href": "posts/03wk-1.html#c.-step1-net-설계-모델링",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. Step1: net 설계 (모델링)",
    "text": "C. Step1: net 설계 (모델링)\n- 최초의 곡선을 그려보자. (\\(net: x \\to yhat\\) 을 수행하는 네트워크를 설계해보자는 의미)\n\nw0hat = -0.8\nw1hat = -0.3\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(w0hat + w1hat*x),'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n- w0hat + w1hat*x 이 부분을 torch.nn.Linear(bias = False)로 구현\n\nX = torch.concat([torch.ones(2000).reshape(-1,1),x],axis=1)\nl1 = torch.nn.Linear(in_features=2, out_features=1, bias = False)\nl1.weight\n\nParameter containing:\ntensor([[-0.0370, -0.1980]], requires_grad=True)\n\n\n\nl1.weight.data = torch.tensor([[-0.8,  -0.3]])\n\n\nl1(X), w0hat + w1hat*x # 똑같죠\n\n(tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]], grad_fn=&lt;MmBackward0&gt;),\n tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]]))\n\n\n- w0hat + w1hat*x 이 부분을 torch.nn.Linear(bias = True)로 구현\n\n#X = torch.concat([torch.ones(2000).reshape(-1,1),x],axis=1)\nl1 = torch.nn.Linear(in_features=1, out_features=1)\nl1.weight, l1.bias\n\n(Parameter containing:\n tensor([[-0.0153]], requires_grad=True),\n Parameter containing:\n tensor([-0.4743], requires_grad=True))\n\n\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\nl1(x), w0hat + w1hat*x # 이것도 똑같죠!\n\n(tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]]))\n\n\n- 내가만든 sigmoid 대신에 토치에서 제공하는 sigmoid 사용\n\na1 = torch.nn.Sigmoid()\n\n\nsigmoid(l1(x)), a1(l1(x)) # 똑같아요\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 지금까지의 구현 확인\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(w0hat + w1hat*x),'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.plot(x,a1(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve with $(a_1 \\circ l_1)(x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 관찰: 지금 아래의 구조이다.\n\\[{\\boldsymbol x} \\overset{l_1}{\\to} {\\boldsymbol u} \\overset{a_1}{\\to} {\\boldsymbol v} = \\hat{\\boldsymbol y}\\]\n- 소망: 함수 \\(l_1, a_1\\) 의 합성을 하나로 묶어서\n\\[(a_1\\circ l_1)({\\boldsymbol x}) := net({\\boldsymbol x})\\]\n이러한 기능을 하는 하나의 함수 \\(net\\)을 만들 수 없을까?\n\nnet = torch.nn.Sequential(l1,a1) #l1을 취하고 그다음에 a1을 취하라는 의미\n\n\nnet(x), a1(l1(x)), sigmoid(w0hat+ w1hat*x)\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]]))\n\n\n- net 살펴보기: 초보버전 – “파이토치 30일만에 완성하기” 이런책에 보면 내용이 나올지도?\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\n\n\n처음에는 선형변환하고, 그담에는 Sigmoid를 수행하라는 의미\n\n- net 살펴보기: 고수버전 – 책 안보고 코딩배우기\n\nset(dir(net)) & {'__call__', '__getitem__'}\n\n{'__call__', '__getitem__'}\n\n\n\n좋은거 가지고 있네 ㅎㅎ\ncallable 이면서 subscriptable 오브젝트..\n\n\nlst = [11,22,33]\nlst.__getitem__(-1) # lst[-1]\n\n33\n\n\n\nsigmoid.__call__(x) # sigmoid(x)\n\ntensor([[0.2689],\n        [0.2691],\n        [0.2693],\n        ...,\n        [0.7307],\n        [0.7309],\n        [0.7311]])\n\n\n\nsigmoid[0] # 난 스크립터블 하지 않은걸? (= 난 리스트처럼 인덱싱 못해요)\n\nTypeError: 'function' object is not subscriptable\n\n\n\nlst(x)# 난 컬러블하지 않은걸? (= 난 함수처럼 입력을 받고 출력을 주는 일은 못해요)\n\nTypeError: 'list' object is not callable\n\n\n\nnet(x) # 컬러블이면서\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet[0],net[1] # 섭스크립터블\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\n_l1, _a1 = net # 언패킹!! (섭스크립터블하니까..)\n\n\n_l1.weight, _l1.bias # 내가 설정한 웨이트도 그대로 들어가있음\n\n(Parameter containing:\n tensor([[-0.3000]], requires_grad=True),\n Parameter containing:\n tensor([-0.8000], requires_grad=True))"
  },
  {
    "objectID": "posts/03wk-1.html#d.-step-14",
    "href": "posts/03wk-1.html#d.-step-14",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. Step 1~4",
    "text": "D. Step 1~4\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#loss_fn = torch.nn.MSELoss() # -- 이 코드 일단 쓰지 않을게여\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n성공했나?"
  },
  {
    "objectID": "posts/03wk-1.html#a.-좋은-초기값",
    "href": "posts/03wk-1.html#a.-좋은-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 좋은 초기값",
    "text": "A. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#b.-가능성-있는-초기값",
    "href": "posts/03wk-1.html#b.-가능성-있는-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가능성 있는 초기값",
    "text": "B. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#c.-최악의-초기값",
    "href": "posts/03wk-1.html#c.-최악의-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 최악의 초기값",
    "text": "C. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n해결하는 접근법:\n\n컴공스타일: 에폭을 늘려볼까?\n산공스타일: 옵티마이저를 바꿔볼까?\n통계스타일: Loss를 바꿔볼까?"
  },
  {
    "objectID": "posts/03wk-1.html#a.-bce-loss를-사용하여-학습",
    "href": "posts/03wk-1.html#a.-bce-loss를-사용하여-학습",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. BCE Loss를 사용하여 학습",
    "text": "A. BCE Loss를 사용하여 학습\n- BCE loss라는게 있음.\n\nhttps://en.wikipedia.org/wiki/Cross-entropy\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n같은 100 에폭인데 훨씬 잘맞춤..\n- loss수식을 못외우겠다면?\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')"
  },
  {
    "objectID": "posts/03wk-1.html#b.-loss-function-시각화",
    "href": "posts/03wk-1.html#b.-loss-function-시각화",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. Loss Function 시각화",
    "text": "B. Loss Function 시각화\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n- 비교해보자.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)"
  },
  {
    "objectID": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값-1",
    "href": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-0.8470])\n# net[0].weight.data = torch.tensor([[-0.3467]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값-1",
    "href": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-3.0])\n# net[0].weight.data = torch.tensor([[-1.0]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값-1",
    "href": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-10.0])\n# net[0].weight.data = torch.tensor([[-1.0]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#a.-신문기사-데이터의-모티브",
    "href": "posts/03wk-1.html#a.-신문기사-데이터의-모티브",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 신문기사 (데이터의 모티브)",
    "text": "A. 신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/03wk-1.html#b.-가짜데이터",
    "href": "posts/03wk-1.html#b.-가짜데이터",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가짜데이터",
    "text": "B. 가짜데이터\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-1.html#c.-로지스틱으로-적합",
    "href": "posts/03wk-1.html#c.-로지스틱으로-적합",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 로지스틱으로 적합",
    "text": "C. 로지스틱으로 적합\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- Epoch을 10억번으로 설정해도 이건 못 맞출것 같음.\n\n결국 올라가다가 내려가는 언더라잉을 맞춰야 하는데 현재 모형으로는 이걸 표현할 수 없다.\n모형의 표현력이 낮다."
  },
  {
    "objectID": "posts/03wk-1.html#d.-해결책-아이디어-수준만",
    "href": "posts/03wk-1.html#d.-해결책-아이디어-수준만",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 해결책 (아이디어 수준만)",
    "text": "D. 해결책 (아이디어 수준만)\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이야 한다.\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/02wk-2.html#a.-data",
    "href": "posts/02wk-2.html#a.-data",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "A. Data",
    "text": "A. Data\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)"
  },
  {
    "objectID": "posts/02wk-2.html#b.-파이토치를-이용한-학습",
    "href": "posts/02wk-2.html#b.-파이토치를-이용한-학습",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "B. 파이토치를 이용한 학습",
    "text": "B. 파이토치를 이용한 학습\n- 외우세여\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n- 결과 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#c.-step2의-수정",
    "href": "posts/02wk-2.html#c.-step2의-수정",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "C. Step2의 수정",
    "text": "C. Step2의 수정\n- 수정된 코드\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    #loss = torch.mean((y-yhat)**2) \n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#d.-step1의-수정-net의-이용",
    "href": "posts/02wk-2.html#d.-step1의-수정-net의-이용",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "D. Step1의 수정 – net의 이용",
    "text": "D. Step1의 수정 – net의 이용\n- net 오브젝트란?\n원래 yhat을 이런식으로 구했는데 ~\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\n(X@What.data)[:5]\n\ntensor([[-29.8210],\n        [-28.6210],\n        [-24.9730],\n        [-21.2390],\n        [-19.7920]])\n\n\n이런식으로도 구할수 있음!\n\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\n\n\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet(X)[:5]\n\ntensor([[-29.8210],\n        [-28.6210],\n        [-24.9730],\n        [-21.2390],\n        [-19.7920]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 학습\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#e.-step4의-수정-optimizer의-이용",
    "href": "posts/02wk-2.html#e.-step4의-수정-optimizer의-이용",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "E. Step4의 수정 – optimizer의 이용",
    "text": "E. Step4의 수정 – optimizer의 이용\n기존코드의 에폭별분해\n- 준비과정\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n- 에폭별분해\n(미분전) – step1~2 완료\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = None\n\n\n(미분후, 업데이트 진행전) – step3 완료\n\nloss.backward()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 진행후) – step4 의 첫째줄 완료\n\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 완료 후 초기화까지 끝냄) – step4 의 두번째줄 완료\n\nnet.weight.grad = None\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = None\n\n\n새로운코드의 에폭별분해\n- 준비과정 – 옵티마이저라는 오브젝트를 셋팅한다!\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step3을 위한 사전준비 \noptimizr = torch.optim.SGD(params=net.parameters(),lr=0.1)\n\n- 에폭별분해\n(미분전) – step1~2 완료\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = None\n\n\n(미분후, 업데이트 진행전) – step3 완료\n\nloss.backward()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 진행후) – step4 의 첫째줄 완료\n\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 완료 후 초기화까지 끝냄) – step4 의 두번째줄 완료\n\n#net.weight.grad = None\noptimizr.zero_grad()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = None\n\n\n최종코드\n- 학습\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/01wk-1.html#a.-최하니",
    "href": "posts/01wk-1.html#a.-최하니",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. 최하니",
    "text": "A. 최하니\n\nhani1 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nhani1\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani1)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([2.9308e-09, 1.0000e+00]))\n\n\n\nhani2 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani2.jpeg?raw=true').content)\nhani2\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani2)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([8.9153e-06, 9.9999e-01]))\n\n\n\nhani3 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani3.jpg?raw=true').content)\nhani3\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani3)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([3.9399e-04, 9.9961e-01]))"
  },
  {
    "objectID": "posts/01wk-1.html#b.-인터넷-고양이",
    "href": "posts/01wk-1.html#b.-인터넷-고양이",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. 인터넷 고양이",
    "text": "B. 인터넷 고양이\n\ncat1 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat1.png?raw=true').content)\ncat1\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat1)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([1.0000e+00, 2.2026e-11]))\n\n\n\ncat2 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat2.jpeg?raw=true').content)\ncat2\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat2)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([1.0000e+00, 9.4345e-07]))"
  },
  {
    "objectID": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "href": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. Step1: DLS(=데이터) 준비",
    "text": "A. Step1: DLS(=데이터) 준비\n\ndls = ImageDataLoaders.from_folder(\n    path = './images',\n    train='train',\n    valid_pct = 0.2,\n    item_tfms=Resize(224),\n)\n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/01wk-1.html#b.-step2-러너생성",
    "href": "posts/01wk-1.html#b.-step2-러너생성",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. Step2: 러너생성",
    "text": "B. Step2: 러너생성\n\nlrnr = vision_learner(\n    dls = dls,\n    arch = resnet34,\n    metrics = accuracy\n)"
  },
  {
    "objectID": "posts/01wk-1.html#c.-step3-학습",
    "href": "posts/01wk-1.html#c.-step3-학습",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "C. Step3: 학습",
    "text": "C. Step3: 학습\n\nlrnr.fine_tune(7)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.346890\n0.969989\n0.657534\n00:11\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.734809\n0.817061\n0.698630\n00:10\n\n\n1\n0.581782\n0.937060\n0.739726\n00:11\n\n\n2\n0.426661\n0.901986\n0.835616\n00:12\n\n\n3\n0.332050\n0.899157\n0.835616\n00:10\n\n\n4\n0.263004\n0.844802\n0.849315\n00:10\n\n\n5\n0.220254\n0.762331\n0.849315\n00:11\n\n\n6\n0.185242\n0.716601\n0.849315\n00:11"
  },
  {
    "objectID": "posts/01wk-1.html#d.-step4-예측",
    "href": "posts/01wk-1.html#d.-step4-예측",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "D. Step4: 예측",
    "text": "D. Step4: 예측\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninter = Interpretation.from_learner(lrnr)\ninter.plot_top_losses(16)"
  },
  {
    "objectID": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "href": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "#. 크롤링을 활용한 이미지 자료 분석",
    "text": "#. 크롤링을 활용한 이미지 자료 분석\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것, 단 (iu,hynn)는 제외)\n(2) ImageDataLoaders.from_folder() 를 이용하여 dls를 만들고 dls.show_batch()를 이용하여 만들어진 이미지를 확인하라.\n(3) vision_learner()를 이용하여 lrnr를 만들고 lrnr.fine_tune()을 이용하여 학습하라. 이때 모형의 arch는 resnet34를 사용하라.\n(4) requests.get()을 이용하여 (1)의 키워드에 해당하는 새로운 이미지를 한장씩 다운받고 (3)에서 학습한 lrnr를 이용하여 예측하라.\n\n제출은 ipynb파일로 할 것. 혹은 스크린샷을 제출해도 괜찮음."
  },
  {
    "objectID": "posts/05wk-2.html#a.-기존모형에-대한-불만",
    "href": "posts/05wk-2.html#a.-기존모형에-대한-불만",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "A. 기존모형에 대한 불만",
    "text": "A. 기존모형에 대한 불만\n\n- 왜 28 \\(\\times\\) 28 이미지를 784개의 벡터로 만든 다음에 모형을 돌려야 하는가?\n- 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌\n- observation의 차원은 \\(784\\)가 아니라 \\(1\\times (28\\times 28)\\)이 되어야 맞다."
  },
  {
    "objectID": "posts/05wk-2.html#b.-새로운-아키텍처의-제시",
    "href": "posts/05wk-2.html#b.-새로운-아키텍처의-제시",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "B. 새로운 아키텍처의 제시",
    "text": "B. 새로운 아키텍처의 제시\n- 예전 아키텍처들\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,256)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,256)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 아키텍처들의 공통점?\n\n\\(l_1\\): 선형변환, feature를 뽑아내는 역할 (뻥튀기 혹은 요약)\n\\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화\n\\(l_2\\): 선형변환, 뻥튀기된 feature를 요약 하는 역할 (=데이터를 요약하는 역할)\n\n- 새로운 아키텍처\n\n\\(conv\\): feature를 뽑아내는 역할 (뻥튀기 혹은 요약) (2d ver \\(l_1\\) 느낌)\n\\(relu\\):\n\\(pooling\\): 데이터를 요약하는 역할"
  },
  {
    "objectID": "posts/05wk-2.html#c.-conv-레이어-선형변환의-2d-버전",
    "href": "posts/05wk-2.html#c.-conv-레이어-선형변환의-2d-버전",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "C. CONV 레이어 (선형변환의 2D 버전)",
    "text": "C. CONV 레이어 (선형변환의 2D 버전)\n- 우선 연산하는 방법만 살펴보자.\n(예시1)\n\ntorch.manual_seed(43052)\nconv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\nconv.weight.data, conv.bias.data\n\n(tensor([[[[-0.1733, -0.4235],\n           [ 0.1802,  0.4668]]]]),\n tensor([0.2037]))\n\n\n\n_X = torch.arange(0,4).reshape(1,1,2,2).float() # 2,2 흑백이미지. \n_X\n\ntensor([[[[0., 1.],\n          [2., 3.]]]])\n\n\n\n(-0.1733)*0 + (-0.4235)*1 +\\\n(0.1802)*2 + (0.4668)*3 + 0.2037\n\n1.541\n\n\n\nconv(_X)\n\ntensor([[[[1.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시2) 잘하면 평균도 계산하겠다?\n\nconv.weight.data = torch.tensor([[[[1/4, 1/4],[1/4,1/4]]]])\nconv.bias.data = torch.tensor([0.0])\n\n\nconv(_X) , (0+1+2+3)/4\n\n(tensor([[[[1.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;), 1.5)\n\n\n(예시3) 이동평균?\n\n_X = torch.arange(0,25).float().reshape(1,1,5,5) \n_X\n\ntensor([[[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]])\n\n\n\nconv(_X)\n\ntensor([[[[ 3.,  4.,  5.,  6.],\n          [ 8.,  9., 10., 11.],\n          [13., 14., 15., 16.],\n          [18., 19., 20., 21.]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시4) window size가 증가한다면? (2d의 이동평균느낌)\n\nconv = torch.nn.Conv2d(1,1,(3,3)) # 입력1, 출력1, (3,3) window size\nconv.bias.data = torch.tensor([0.0])\nconv.weight.data = torch.tensor([[[[1/9,1/9,1/9],[1/9,1/9,1/9],[1/9,1/9,1/9]]]])\n\n\n_X,conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n           [ 5.,  6.,  7.,  8.,  9.],\n           [10., 11., 12., 13., 14.],\n           [15., 16., 17., 18., 19.],\n           [20., 21., 22., 23., 24.]]]]),\n tensor([[[[ 6.0000,  7.0000,  8.0000],\n           [11.0000, 12.0000, 13.0000],\n           [16.0000, 17.0000, 18.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(1+2+3+6+7+8+11+12+13)/9\n\n7.0\n\n\n(예시5) 2개의 이미지\n\nconv = torch.nn.Conv2d(1,1,(3,3)) # 입력1, 출력1, (3,3) window size\nconv.bias.data = torch.tensor([0.0])\nconv.weight.data = torch.tensor([[[[1/9,1/9,1/9],[1/9,1/9,1/9],[1/9,1/9,1/9]]]])\n\n\n_X = torch.arange(0,50).float().reshape(2,1,5,5) \n_X\n\ntensor([[[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]],\n\n\n        [[[25., 26., 27., 28., 29.],\n          [30., 31., 32., 33., 34.],\n          [35., 36., 37., 38., 39.],\n          [40., 41., 42., 43., 44.],\n          [45., 46., 47., 48., 49.]]]])\n\n\n\nconv(_X)\n\ntensor([[[[ 6.0000,  7.0000,  8.0000],\n          [11.0000, 12.0000, 13.0000],\n          [16.0000, 17.0000, 18.0000]]],\n\n\n        [[[31.0000, 32.0000, 33.0000],\n          [36.0000, 37.0000, 38.0000],\n          [41.0000, 42.0000, 43.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시6) 피처뻥튀기\n\n_X = torch.tensor([1.0,1.0,1.0,1.0]).reshape(1,1,2,2)\n_X\n\ntensor([[[[1., 1.],\n          [1., 1.]]]])\n\n\n\nconv = torch.nn.Conv2d(1,8,(2,2))\nconv.weight.data.shape,conv.bias.data.shape\n\n(torch.Size([8, 1, 2, 2]), torch.Size([8]))\n\n\n\nconv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=&lt;ViewBackward0&gt;)\n\n\n\ntorch.sum(conv.weight.data[0,...])+conv.bias.data[0],\\\ntorch.sum(conv.weight.data[1,...])+conv.bias.data[1]\n\n(tensor(-0.3464), tensor(0.2739))\n\n\n결국 아래를 계산한다는 의미\n\ntorch.sum(conv.weight.data,axis=(2,3)).reshape(-1) + conv.bias.data\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345])\n\n\n\nconv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=&lt;ViewBackward0&gt;)"
  },
  {
    "objectID": "posts/05wk-2.html#d.-relu-2d",
    "href": "posts/05wk-2.html#d.-relu-2d",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "D. ReLU (2d)",
    "text": "D. ReLU (2d)\n\n_X = torch.randn(25).reshape(1,1,5,5)\n_X\n\ntensor([[[[-0.1057, -1.3722,  0.4665, -0.7705, -0.6630],\n          [-0.4631,  0.4362,  0.4981, -0.9319, -0.3996],\n          [-1.3803,  1.0685,  0.4247, -0.3227,  0.4711],\n          [ 0.7154,  0.4969,  1.1464, -0.0625, -0.0356],\n          [ 0.6259,  0.5899,  0.0306,  1.5095, -0.2842]]]])\n\n\n\na1=torch.nn.ReLU()\n\n\na1(_X)\n\ntensor([[[[0.0000, 0.0000, 0.4665, 0.0000, 0.0000],\n          [0.0000, 0.4362, 0.4981, 0.0000, 0.0000],\n          [0.0000, 1.0685, 0.4247, 0.0000, 0.4711],\n          [0.7154, 0.4969, 1.1464, 0.0000, 0.0000],\n          [0.6259, 0.5899, 0.0306, 1.5095, 0.0000]]]])"
  },
  {
    "objectID": "posts/05wk-2.html#e.-maxpooling-레이어",
    "href": "posts/05wk-2.html#e.-maxpooling-레이어",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "E. Maxpooling 레이어",
    "text": "E. Maxpooling 레이어\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n\n\n_X = torch.arange(16).float().reshape(1,1,4,4) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]]]]),\n tensor([[[[ 5.,  7.],\n           [13., 15.]]]]))\n\n\n\n_X = torch.arange(25).float().reshape(1,1,5,5) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n           [ 5.,  6.,  7.,  8.,  9.],\n           [10., 11., 12., 13., 14.],\n           [15., 16., 17., 18., 19.],\n           [20., 21., 22., 23., 24.]]]]),\n tensor([[[[ 6.,  8.],\n           [16., 18.]]]]))\n\n\n\n_X = torch.arange(36).float().reshape(1,6,6) \n\n\n_X, _maxpooling(_X)\n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9., 10., 11.],\n          [12., 13., 14., 15., 16., 17.],\n          [18., 19., 20., 21., 22., 23.],\n          [24., 25., 26., 27., 28., 29.],\n          [30., 31., 32., 33., 34., 35.]]]),\n tensor([[[ 7.,  9., 11.],\n          [19., 21., 23.],\n          [31., 33., 35.]]]))"
  },
  {
    "objectID": "posts/05wk-2.html#a.-conv2d",
    "href": "posts/05wk-2.html#a.-conv2d",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "A. Conv2d",
    "text": "A. Conv2d\n\nc1 = torch.nn.Conv2d(1,16,(5,5))\nprint(X.shape)\nprint(c1(X).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/05wk-2.html#b.-relu",
    "href": "posts/05wk-2.html#b.-relu",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "B. ReLU",
    "text": "B. ReLU\n\na1 = torch.nn.ReLU()\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/05wk-2.html#c.-maxpool2d",
    "href": "posts/05wk-2.html#c.-maxpool2d",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "C. MaxPool2D",
    "text": "C. MaxPool2D\n\nm1 =  torch.nn.MaxPool2d((2,2)) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])"
  },
  {
    "objectID": "posts/05wk-2.html#d.-적당히-마무리하고-시그모이드-태우자",
    "href": "posts/05wk-2.html#d.-적당히-마무리하고-시그모이드-태우자",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "D. 적당히 마무리하고 시그모이드 태우자",
    "text": "D. 적당히 마무리하고 시그모이드 태우자\n- 펼치자.\n(방법1)\n\nm1(a1(c1(X))).reshape(-1,2304).shape\n\ntorch.Size([12665, 2304])\n\n\n\n16*12*12 \n\n2304\n\n\n(방법2)\n\nflttn = torch.nn.Flatten()\n\n\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\n\n\n- 2304 \\(\\to\\) 1 로 차원축소하는 선형레이어를 설계\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\n\n\n- 시그모이드\n\na2 = torch.nn.Sigmoid()\n\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\nprint(a1(l1(flttn(m1(a1(c1(X)))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\ntorch.Size([12665, 1])"
  },
  {
    "objectID": "posts/05wk-2.html#e.-학습",
    "href": "posts/05wk-2.html#e.-학습",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "E. 학습",
    "text": "E. 학습\n- 네트워크 설계\n\nnet = torch.nn.Sequential(\n    c1, # 2d: 컨볼루션(선형변환), 피처 뻥튀기 \n    a1, # 2d: 렐루(비선형변환)\n    m1, # 2d: 맥스풀링: 데이터요약\n    flttn, # 2d-&gt;1d \n    l1, # 1d: 선형변환\n    a2 # 1d: 시그모이드(비선형변환) \n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\nfor epoc in range(50): \n    ## 1\n    yhat = net(X) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(net(X).data,'.')\nplt.title('Traning Set',size=15)\n\nText(0.5, 1.0, 'Traning Set')\n\n\n\n\n\n\n\n\n\n\nplt.plot(yy)\nplt.plot(net(XX).data,'.')\nplt.title('Test Set',size=15)\n\nText(0.5, 1.0, 'Test Set')\n\n\n\n\n\n\n\n\n\n\n[np.prod(list(para.shape)) for para in net.parameters()]\n\n[400, 16, 2304, 1]"
  },
  {
    "objectID": "posts/05wk-2.html#a.-지도학습",
    "href": "posts/05wk-2.html#a.-지도학습",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "A. 지도학습",
    "text": "A. 지도학습\n- 우리가 수업에서 다루는 데이터는 주로 아래와 같은 느낌이다.\n\n데이터는 \\((X,y)\\)의 형태로 정리되어 있다.\n\\(y\\)는 우리가 관심이 있는 변수이다. 즉 우리는 \\(y\\)를 적절하게 추정하는 것에 관심이 있다.\n\\(X\\)는 \\(y\\)를 추정하기 위해 필요한 정보이다.\n\n\n\n\n\n\n\n\n\n\n\n\\(X\\) = 설명변수 = 독립변수\n\\(y\\) = 반응변수 = 종속변수\n비고\n순서\n예시\n\n\n\n\n이미지\n카테고리\n합성곱신경망\n상관없음\n개/고양이 이미지 구분\n\n\n유저,아이템\n평점\n추천시스템\n상관없음\n넷플릭스 영화추천\n\n\n과거~오늘까지의주가\n내일주가\n순환신경망\n순서상관있음\n주가예측\n\n\n처음 \\(m\\)개의 단어(혹은 문장)\n이후 1개의 단어(혹은 문장)\n순환신경망\n순서상관있음\n챗봇, 텍스트생성\n\n\n처음 \\(m\\)개의 단어(혹은 문장)\n카테고리\n순환신경망\n순서상관있음\n영화리뷰 텍스트 감정분류\n\n\n\n- 이러한 문제상황, 즉 \\((X,y)\\)가 주어졌을때 \\(X \\to y\\)를 추정하는 문제를 supervised learning 이라한다."
  },
  {
    "objectID": "posts/05wk-2.html#b.-모델이란",
    "href": "posts/05wk-2.html#b.-모델이란",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "B. 모델이란?",
    "text": "B. 모델이란?\n\n모델이란 단어는 제 발작버튼이었어요..\n\n- 통계학에서 모델은 y와 x의 관계를 의미하며 오차항의 설계를 포함하는 개념이다. 이는 통계학이 “데이터 = 정보 + 오차”의 관점을 유지하기 때문이다. 따라서 통계학에서 모델링이란\n\\[y_i = net(x_i) + \\epsilon_i\\]\n에서 (1) 적절한 함수 \\(net\\)를 선택하는 일 (2) 적절한 오차항 \\(\\epsilon_i\\) 을 설계하는일 모두를 포함한다.\n- 딥러닝 혹은 머신러닝에서 모델은 단순히\n\\[y_i \\approx net(x_i)\\]\n를 의미하는 경우가 많다. 즉 “model=net”라고 생각해도 무방하다. 이 경우 “모델링”이란 단순히 적절한 \\(net\\)을 설계하는 것만을 의미할 경우가 많다.\n- 그래서 생긴일\n\n통계학교재 특: 분류문제와 회귀문제를 엄밀하게 구분하지 않는다. 사실 오차항만 다를뿐이지 크게보면 같은 회귀모형이라는 관점이다. 그래서 일반화선형모형(GLM)이라는 용어를 쓴다.\n머신러닝/딥러닝교재 특: 회귀문제와 분류문제를 구분해서 설명한다. (표도 만듦) 이는 오차항에 대한 기술을 모호하게 하여 생기는 현상이다."
  },
  {
    "objectID": "posts/05wk-2.html#c.-학습이란",
    "href": "posts/05wk-2.html#c.-학습이란",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "C. 학습이란?",
    "text": "C. 학습이란?\n- 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “규칙” 혹은 “원리”를 찾는 것이다.\n\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “맵핑”을 찾는 것이다.\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “함수”을 찾는 것이다. 즉 \\(y\\approx f(X)\\)가 되도록 만드는 \\(f\\)를 잘 찾는 것이다. (이 경우 “함수를 추정한다”라고 표현)\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “모델” 혹은 “모형”을 찾는 것이다. 즉 \\(y\\approx model(X)\\)가 되도록 만드는 \\(model\\)을 잘 찾는 것이다. (이 경우 “모형을 학습시킨다”라고 표현)\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “네트워크”을 찾는 것이다. 즉 \\(y\\approx net(X)\\)가 되도록 만드는 \\(net\\)을 잘 찾는 것이다. (이 경우 “네트워크를 학습시킨다”라고 표현)\n\n- prediction이란 학습과정에서 찾은 “규칙” 혹은 “원리”를 \\(X\\)에 적용하여 \\(\\hat{y}\\)을 구하는 과정이다. 학습과정에서 찾은 규칙 혹은 원리는 \\(f\\),\\(model\\),\\(net\\) 으로 생각가능한데 이에 따르면 아래가 성립한다.\n\n\\(\\hat{y} = f(X)\\)\n\\(\\hat{y} = model(X)\\)\n\\(\\hat{y} = net(X)\\)"
  },
  {
    "objectID": "posts/05wk-2.html#d.-haty를-부르는-다양한-이름",
    "href": "posts/05wk-2.html#d.-haty를-부르는-다양한-이름",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "D. \\(\\hat{y}\\)를 부르는 다양한 이름",
    "text": "D. \\(\\hat{y}\\)를 부르는 다양한 이름\n- \\(\\hat{y}\\)는 \\(X\\)가 주어진 자료에 있는 값인지 아니면 새로운 값 인지에 따라 지칭하는 이름이 미묘하게 다르다.\n\n\\(X \\in data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, fitted value 라고 부른다.\n\\(X \\notin data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, predicted value with new data 라고 부른다.\n\n- 경우1은 “\\(loss\\) = \\(y\\) 와 \\(\\hat{y}\\) 의 차이” 를 정의할 수 있으나 경우2는 그렇지 않다."
  },
  {
    "objectID": "posts/05wk-2.html#e.-다양한-코드들",
    "href": "posts/05wk-2.html#e.-다양한-코드들",
    "title": "05wk-2: 합성곱신경망 (1)",
    "section": "E. 다양한 코드들",
    "text": "E. 다양한 코드들\n- 파이썬 코드..\n#Python\npredictor.fit(X,y) # autogluon 에서 \"학습\"을 의미하는 과정\nmodel.fit(X,y) # sklearn 에서 \"학습\"을 의미하는 과정\nlearner.learn() # fastai 에서 \"학습\"을 의미하는 과정\nlearner.fine_tune(1) # fastai 에서 \"부분학습\"을 의미하는 과정\nlearner.predict(cat1) # fastai 에서 \"예측\"을 의미하는 과정 \nmodel.fit(x, y, batch_size=32, epochs=10) # keras에서 \"학습\"을 의미하는 과정\nmodel.predict(test_img) # keras에서 \"예측\"을 의미하는 과정 \n- R 코드..\n# R\nols &lt;- lm(y~x) # 선형회귀분석에서 학습을 의미하는 함수\nols$fitted.values # 선형회귀분석에서 yhat을 출력 \npredict(ols, newdata=test) # 선형회귀분석에서 test에 대한 예측값을 출력하는 함수\nols$coef # 선형회귀분석에서 weight를 확인하는 방법"
  },
  {
    "objectID": "posts/04wk-2.html#a.-오버피팅",
    "href": "posts/04wk-2.html#a.-오버피팅",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "A. 오버피팅",
    "text": "A. 오버피팅\n- 오버피팅이란?\n\n위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”.\n제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상."
  },
  {
    "objectID": "posts/04wk-2.html#b.-오버피팅-예시",
    "href": "posts/04wk-2.html#b.-오버피팅-예시",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "B. 오버피팅 예시",
    "text": "B. 오버피팅 예시\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\nmodel: \\(y_i = (0\\times x_i) + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0,0.01^2)\\)\n\ntorch.manual_seed(5) \nx = torch.linspace(0,1,100).reshape(100,1)\ny = torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y,'--o',alpha=0.5)\n\n\n\n\n\n\n\n\n\ny는 그냥 정규분포에서 생성한 오차이므로 \\(X \\to y\\) 로 향하는 규칙따위는 없음\n\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat=net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    net.zero_grad() \n\n\nplt.plot(x,y,'--o',alpha=0.5)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\n우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 \\(\\to\\) 오버피팅 (underlying이 아니라 오차항을 따라가고 있음)"
  },
  {
    "objectID": "posts/04wk-2.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/04wk-2.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "C. 오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "C. 오버피팅이라는 뚜렷한 증거! (train / test)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx = x_all[:80] \ny = y_all[:80]\nxx = x_all[80:]\nyy = y_all[80:]\nplt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\nplt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\nplt.legend()\n\n\n\n\n\n\n\n\n- train만 학습\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\nplt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\nplt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\nplt.legend()\n\n\n\n\n\n\n\n\n\ntrain에서는 잘 맞추는듯이 보인다.\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\nplt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\nplt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\nplt.plot(xx,net(xx).data,label=\"predicted values, predicted values with new data\",color=\"C1\")\nplt.legend()\n\n\n\n\n\n\n\n\n\ntrain은 그럭저럭 따라가지만 test에서는 엉망이다. \\(\\to\\) overfit"
  },
  {
    "objectID": "posts/04wk-2.html#d.-시벤코정리의-올바른-이해",
    "href": "posts/04wk-2.html#d.-시벤코정리의-올바른-이해",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\n\n\n\n\n\n시벤코정리의 항변(?) (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 continuous mapping\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다 (즉 마음만 먹으면 loss를 0에 가깝도록 만들 수 있다는 의다) 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 심층신경망(DNN)이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times p}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 즉\n\\[{\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 근사시킨 네트워크라고 할지라도\n\\[{\\bf XX}_{m \\times p} \\to {\\bf yy}_{m\\times q}\\]\n는 엉터리로 나올 수 있다. 시벤코는 넓은 신경망이 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다. 넓은 신경망이 우수한 신경망1이라는 주장을 한적은 없다.\n\n\n1 여기에서 우수하다는 말은 여러의미가 있어요, 오버피팅이 없는 신경망이라든가, 경제적인 신경망이라든가..\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/04wk-2.html#a.-오버피팅의-해결",
    "href": "posts/04wk-2.html#a.-오버피팅의-해결",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "A. 오버피팅의 해결",
    "text": "A. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터 – 재활용\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx = x_all[:80] \ny = y_all[:80]\nxx = x_all[80:]\nyy = y_all[80:]\nplt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\nplt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\nplt.legend()\n\n\n\n\n\n\n\n\n- 학습\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(net(x),y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화 (잘못된 사용)\n\nplt.plot(x,y,'o')\nplt.plot(xx,yy,'o')\nplt.plot(x,net(x).data,'--',color='C0') \nplt.title(f\"net.training = {net.training}\",fontsize=15)\n\nText(0.5, 1.0, 'net.training = True')\n\n\n\n\n\n\n\n\n\n\nnet에 드랍아웃이 포함되어 있다면, net.training  == True 일때 결과가 엉망으로 나옴.\n왜??\n\n- 결과시각화 (올바른 사용)\n\nnet.training\n\nTrue\n\n\n\nnet.eval()\nnet.training\n\nFalse\n\n\n\nplt.plot(x,y,'o')\nplt.plot(xx,yy,'o')\nplt.plot(x,net(x).data,'--',color='C0') \nplt.plot(xx,net(xx).data,'--',color='C1') \nplt.title(f\"net.training = {net.training}\",fontsize=15)\n\nText(0.5, 1.0, 'net.training = False')\n\n\n\n\n\n\n\n\n\n\n이게 제대로 된 결과시각화임!"
  },
  {
    "objectID": "posts/04wk-2.html#b.-드랍아웃-레이어",
    "href": "posts/04wk-2.html#b.-드랍아웃-레이어",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "B. 드랍아웃 레이어",
    "text": "B. 드랍아웃 레이어\n\nu = torch.randn(20).reshape(10,2)\nu\n\ntensor([[ 1.2686, -0.8109],\n        [-1.0100,  0.1346],\n        [-1.9911, -0.9007],\n        [ 0.7675, -0.7510],\n        [ 2.1963, -0.4903],\n        [-1.5218,  0.7236],\n        [-0.4238,  0.0079],\n        [ 1.5566,  1.6662],\n        [ 1.4546,  0.2123],\n        [-1.5117,  0.9293]])\n\n\n\nd = torch.nn.Dropout(0.9)\nd(u)\n\ntensor([[12.6862, -0.0000],\n        [-0.0000,  0.0000],\n        [-0.0000, -0.0000],\n        [ 0.0000, -0.0000],\n        [ 0.0000, -0.0000],\n        [-0.0000,  0.0000],\n        [-0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [-0.0000,  0.0000]])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n\n- 드랍아웃레이어 정리\n\n구조: 입력 -&gt; 드랍아웃레이어 -&gt; 출력\n역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정\n효과: 오버피팅을 억제하는 효과가 있음 (왜??) &lt;– 이거 너무 시간이 없어서 대충 설명했는데요.. 잘 이해가 안되시면 2023-기계학습활용-11wk-43, 2023-기계학습활용-12wk-44 참고하시면 될 겁니다. 그래도 이해가 안되면 일단은 외우세요. (진짜 궁금하시면 따로 물어보세요.. 제가 이걸 설명할 시간이 없을것 같아요.. 죄송합니다)\n의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 랜덤으로 결정됨.\n느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨\n\n\n오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다..\n\n- ReLU + dropout의 특이한 성질\n\ndef my_dropout(x):\n    x[:5,[0]] = torch.zeros(5).reshape(-1,1)\n    x[5:,[1]] = torch.zeros(5).reshape(-1,1)\n    return 2*x\n\nrelu = torch.nn.ReLU()\nsig = torch.nn.Sigmoid()\n\n\nrelu(my_dropout(u)), my_dropout(relu(u))\n\n(tensor([[0.0000, 0.0000],\n         [0.0000, 0.2693],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [3.1132, 0.0000],\n         [2.9091, 0.0000],\n         [0.0000, 0.0000]]),\n tensor([[0.0000, 0.0000],\n         [0.0000, 0.2693],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [3.1132, 0.0000],\n         [2.9091, 0.0000],\n         [0.0000, 0.0000]]))\n\n\n\nsig(my_dropout(u)), my_dropout(sig(u))\n\n(tensor([[0.5000, 0.1650],\n         [0.5000, 0.5669],\n         [0.5000, 0.1417],\n         [0.5000, 0.1821],\n         [0.5000, 0.2728],\n         [0.0455, 0.5000],\n         [0.2999, 0.5000],\n         [0.9574, 0.5000],\n         [0.9483, 0.5000],\n         [0.0464, 0.5000]]),\n tensor([[0.0000, 0.6154],\n         [0.0000, 1.0672],\n         [0.0000, 0.5778],\n         [0.0000, 0.6412],\n         [0.0000, 0.7597],\n         [0.3584, 0.0000],\n         [0.7912, 0.0000],\n         [1.6517, 0.0000],\n         [1.6214, 0.0000],\n         [0.3614, 0.0000]]))\n\n\n\n드랍아웃은 히든레이어사이, 즉 활성화 함수 바로 뒤에 오는게 맞음. 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함."
  },
  {
    "objectID": "posts/04wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/04wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 03kw-2에서 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n\n\n\n\n\n\nImportant\n\n\n\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\n\n\n\n\n\n\nImportant\n\n\n\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. (Rosenblatt et al. 1962)\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n\n\nRosenblatt, Frank et al. 1962. Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. Vol. 55. Spartan books Washington, DC.\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/04wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(다이어그램표현)\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]